{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "13_Final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "Ox_VU3INvf6l"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6SVIEM-5Ho7",
        "colab_type": "text"
      },
      "source": [
        "# Importing packages and downloading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKcspvHknhno",
        "colab_type": "code",
        "outputId": "25a7c72f-925c-4e12-b738-223959918ebe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHl9E-JlnlT0",
        "colab_type": "code",
        "outputId": "39b2dd0c-1c10-46f8-9ade-9aec90258645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "## Downloading the dataset.\n",
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-11 07:13:45--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip’\n",
            "\n",
            "tiny-imagenet-200.z 100%[===================>] 236.61M  3.89MB/s    in 57s     \n",
            "\n",
            "2019-04-11 07:14:42 (4.18 MB/s) - ‘tiny-imagenet-200.zip’ saved [248100043/248100043]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz2h7CxmyjMb",
        "colab_type": "code",
        "outputId": "143bc243-c514-4ec1-b257-cf343a9969b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "## Unzipping dataset\n",
        "!ls\n",
        "!unzip -qq 'tiny-imagenet-200.zip'\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data  tiny-imagenet-200.zip\n",
            "drive  sample_data  tiny-imagenet-200  tiny-imagenet-200.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYgbSmV_npbl",
        "colab_type": "code",
        "outputId": "75daf167-08ad-41ca-f1a1-41405266d4f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "## Downloading CLR package\n",
        "import sys\n",
        "! git clone --recursive https://github.com/bckenstler/CLR.git\n",
        "sys.path.insert(0, '/content/CLR')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CLR'...\n",
            "remote: Enumerating objects: 244, done.\u001b[K\n",
            "remote: Total 244 (delta 0), reused 0 (delta 0), pack-reused 244\u001b[K\n",
            "Receiving objects: 100% (244/244), 1.37 MiB | 1.50 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtLclZIEtoWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAINING_DIR = \"/content/tiny-imagenet-200/train/\"\n",
        "VALIDATION_DIR = \"/content/tiny-imagenet-200/val/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp2Yb2NKn_yi",
        "colab_type": "code",
        "outputId": "ddaf9849-be2d-41d8-abe1-be2ab7752df6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn import preprocessing\n",
        "from keras.utils import np_utils\n",
        "import cv2 as cv\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkJHN8vg5AHC",
        "colab_type": "text"
      },
      "source": [
        "#Getting X_train and Y_train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bcsa8WeCMivU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##When Loading full dataset\n",
        "\n",
        "def load_training_data(training_dir, target_size=None):\n",
        "  SIZE = 64\n",
        "  images = []\n",
        "  labels_list = []\n",
        "\n",
        "  for classtype in os.listdir(training_dir):\n",
        "    img_base = training_dir+classtype+\"/images/\"\n",
        "    for img_name in os.listdir(img_base):\n",
        "      img_path = os.path.join(img_base,img_name)\n",
        "      img_data = cv.imread(img_path)\n",
        "      if target_size:\n",
        "        frac = target_size/SIZE\n",
        "        img_data = cv.resize(img_data,None,fx=frac,fy=frac)\n",
        "      images.append(img_data)\n",
        "      labels_list.append(classtype)\n",
        "      \n",
        "       \n",
        "  images = np.asarray(images)\n",
        "  labels = np.asarray(labels_list)\n",
        "  \n",
        "  print(\"Loaded training images\",images.shape)\n",
        "  print(\"Loaded training labels\",labels.shape)\n",
        "  \n",
        "  return images,labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvlptZoTibXQ",
        "colab_type": "code",
        "outputId": "3de6ab1a-93db-4391-a751-992e3d05fdcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "images, labels = load_training_data(TRAINING_DIR, 64)\n",
        "\n",
        "#Rondomizing the training classes\n",
        "permut = np.random.permutation(len(labels))\n",
        "training_images = images[permut]\n",
        "training_labels = labels[permut]\n",
        "\n",
        "#Encoding labels\n",
        "le = preprocessing.LabelEncoder()\n",
        "le = le.fit(training_labels)\n",
        "training_labels_encoded = le.transform(training_labels)\n",
        "nb_classes = len(le.classes_)\n",
        "\n",
        "X_train = training_images\n",
        "\n",
        "#One Hot Encoding\n",
        "pre_Y_train = training_labels_encoded\n",
        "Y_train = np_utils.to_categorical(pre_Y_train, nb_classes)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded training images (100000, 64, 64, 3)\n",
            "Loaded training labels (100000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWIXUkZJsgno",
        "colab_type": "code",
        "outputId": "a8728bc3-b398-47cb-fe0e-ce8051adff22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3996
        }
      },
      "source": [
        "## For checking the X_train and Y_train and their One Hot Encoding\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(training_labels[8178])\n",
        "plt.imshow(training_images[8178])\n",
        "print(pre_Y_train[8178])\n",
        "print(np.argmax(Y_train[8178]))\n",
        "\n",
        "\n",
        "## Getting a map of classnames and their respective encoded value\n",
        "infer_encoded = list(set(training_labels))\n",
        "infer_encoded_int = le.transform(infer_encoded)\n",
        "infer_encoded_int_list = list(infer_encoded_int)\n",
        "train_class_mapped = zip(infer_encoded,infer_encoded_int_list)\n",
        "train_class_mapped = set(train_class_mapped)\n",
        "train_class_mapped"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000, 64, 64, 3)\n",
            "(100000, 200)\n",
            "n04597913\n",
            "175\n",
            "175\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('n01443537', 0),\n",
              " ('n01629819', 1),\n",
              " ('n01641577', 2),\n",
              " ('n01644900', 3),\n",
              " ('n01698640', 4),\n",
              " ('n01742172', 5),\n",
              " ('n01768244', 6),\n",
              " ('n01770393', 7),\n",
              " ('n01774384', 8),\n",
              " ('n01774750', 9),\n",
              " ('n01784675', 10),\n",
              " ('n01855672', 11),\n",
              " ('n01882714', 12),\n",
              " ('n01910747', 13),\n",
              " ('n01917289', 14),\n",
              " ('n01944390', 15),\n",
              " ('n01945685', 16),\n",
              " ('n01950731', 17),\n",
              " ('n01983481', 18),\n",
              " ('n01984695', 19),\n",
              " ('n02002724', 20),\n",
              " ('n02056570', 21),\n",
              " ('n02058221', 22),\n",
              " ('n02074367', 23),\n",
              " ('n02085620', 24),\n",
              " ('n02094433', 25),\n",
              " ('n02099601', 26),\n",
              " ('n02099712', 27),\n",
              " ('n02106662', 28),\n",
              " ('n02113799', 29),\n",
              " ('n02123045', 30),\n",
              " ('n02123394', 31),\n",
              " ('n02124075', 32),\n",
              " ('n02125311', 33),\n",
              " ('n02129165', 34),\n",
              " ('n02132136', 35),\n",
              " ('n02165456', 36),\n",
              " ('n02190166', 37),\n",
              " ('n02206856', 38),\n",
              " ('n02226429', 39),\n",
              " ('n02231487', 40),\n",
              " ('n02233338', 41),\n",
              " ('n02236044', 42),\n",
              " ('n02268443', 43),\n",
              " ('n02279972', 44),\n",
              " ('n02281406', 45),\n",
              " ('n02321529', 46),\n",
              " ('n02364673', 47),\n",
              " ('n02395406', 48),\n",
              " ('n02403003', 49),\n",
              " ('n02410509', 50),\n",
              " ('n02415577', 51),\n",
              " ('n02423022', 52),\n",
              " ('n02437312', 53),\n",
              " ('n02480495', 54),\n",
              " ('n02481823', 55),\n",
              " ('n02486410', 56),\n",
              " ('n02504458', 57),\n",
              " ('n02509815', 58),\n",
              " ('n02666196', 59),\n",
              " ('n02669723', 60),\n",
              " ('n02699494', 61),\n",
              " ('n02730930', 62),\n",
              " ('n02769748', 63),\n",
              " ('n02788148', 64),\n",
              " ('n02791270', 65),\n",
              " ('n02793495', 66),\n",
              " ('n02795169', 67),\n",
              " ('n02802426', 68),\n",
              " ('n02808440', 69),\n",
              " ('n02814533', 70),\n",
              " ('n02814860', 71),\n",
              " ('n02815834', 72),\n",
              " ('n02823428', 73),\n",
              " ('n02837789', 74),\n",
              " ('n02841315', 75),\n",
              " ('n02843684', 76),\n",
              " ('n02883205', 77),\n",
              " ('n02892201', 78),\n",
              " ('n02906734', 79),\n",
              " ('n02909870', 80),\n",
              " ('n02917067', 81),\n",
              " ('n02927161', 82),\n",
              " ('n02948072', 83),\n",
              " ('n02950826', 84),\n",
              " ('n02963159', 85),\n",
              " ('n02977058', 86),\n",
              " ('n02988304', 87),\n",
              " ('n02999410', 88),\n",
              " ('n03014705', 89),\n",
              " ('n03026506', 90),\n",
              " ('n03042490', 91),\n",
              " ('n03085013', 92),\n",
              " ('n03089624', 93),\n",
              " ('n03100240', 94),\n",
              " ('n03126707', 95),\n",
              " ('n03160309', 96),\n",
              " ('n03179701', 97),\n",
              " ('n03201208', 98),\n",
              " ('n03250847', 99),\n",
              " ('n03255030', 100),\n",
              " ('n03355925', 101),\n",
              " ('n03388043', 102),\n",
              " ('n03393912', 103),\n",
              " ('n03400231', 104),\n",
              " ('n03404251', 105),\n",
              " ('n03424325', 106),\n",
              " ('n03444034', 107),\n",
              " ('n03447447', 108),\n",
              " ('n03544143', 109),\n",
              " ('n03584254', 110),\n",
              " ('n03599486', 111),\n",
              " ('n03617480', 112),\n",
              " ('n03637318', 113),\n",
              " ('n03649909', 114),\n",
              " ('n03662601', 115),\n",
              " ('n03670208', 116),\n",
              " ('n03706229', 117),\n",
              " ('n03733131', 118),\n",
              " ('n03763968', 119),\n",
              " ('n03770439', 120),\n",
              " ('n03796401', 121),\n",
              " ('n03804744', 122),\n",
              " ('n03814639', 123),\n",
              " ('n03837869', 124),\n",
              " ('n03838899', 125),\n",
              " ('n03854065', 126),\n",
              " ('n03891332', 127),\n",
              " ('n03902125', 128),\n",
              " ('n03930313', 129),\n",
              " ('n03937543', 130),\n",
              " ('n03970156', 131),\n",
              " ('n03976657', 132),\n",
              " ('n03977966', 133),\n",
              " ('n03980874', 134),\n",
              " ('n03983396', 135),\n",
              " ('n03992509', 136),\n",
              " ('n04008634', 137),\n",
              " ('n04023962', 138),\n",
              " ('n04067472', 139),\n",
              " ('n04070727', 140),\n",
              " ('n04074963', 141),\n",
              " ('n04099969', 142),\n",
              " ('n04118538', 143),\n",
              " ('n04133789', 144),\n",
              " ('n04146614', 145),\n",
              " ('n04149813', 146),\n",
              " ('n04179913', 147),\n",
              " ('n04251144', 148),\n",
              " ('n04254777', 149),\n",
              " ('n04259630', 150),\n",
              " ('n04265275', 151),\n",
              " ('n04275548', 152),\n",
              " ('n04285008', 153),\n",
              " ('n04311004', 154),\n",
              " ('n04328186', 155),\n",
              " ('n04356056', 156),\n",
              " ('n04366367', 157),\n",
              " ('n04371430', 158),\n",
              " ('n04376876', 159),\n",
              " ('n04398044', 160),\n",
              " ('n04399382', 161),\n",
              " ('n04417672', 162),\n",
              " ('n04456115', 163),\n",
              " ('n04465501', 164),\n",
              " ('n04486054', 165),\n",
              " ('n04487081', 166),\n",
              " ('n04501370', 167),\n",
              " ('n04507155', 168),\n",
              " ('n04532106', 169),\n",
              " ('n04532670', 170),\n",
              " ('n04540053', 171),\n",
              " ('n04560804', 172),\n",
              " ('n04562935', 173),\n",
              " ('n04596742', 174),\n",
              " ('n04597913', 175),\n",
              " ('n06596364', 176),\n",
              " ('n07579787', 177),\n",
              " ('n07583066', 178),\n",
              " ('n07614500', 179),\n",
              " ('n07615774', 180),\n",
              " ('n07695742', 181),\n",
              " ('n07711569', 182),\n",
              " ('n07715103', 183),\n",
              " ('n07720875', 184),\n",
              " ('n07734744', 185),\n",
              " ('n07747607', 186),\n",
              " ('n07749582', 187),\n",
              " ('n07753592', 188),\n",
              " ('n07768694', 189),\n",
              " ('n07871810', 190),\n",
              " ('n07873807', 191),\n",
              " ('n07875152', 192),\n",
              " ('n07920052', 193),\n",
              " ('n09193705', 194),\n",
              " ('n09246464', 195),\n",
              " ('n09256479', 196),\n",
              " ('n09332890', 197),\n",
              " ('n09428293', 198),\n",
              " ('n12267677', 199)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bziyd3av53zi",
        "colab_type": "text"
      },
      "source": [
        "# Getting X_test and Y_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1octEPOz7VpD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_label(val_notations, img_name):\n",
        "  return list(val_notations[val_notations['File'] == img_name]['Class'])[0]\n",
        "\n",
        "import pandas as pd\n",
        "val_notations = pd.read_csv(VALIDATION_DIR + 'val_annotations.txt', sep='\\t', header=None, names=['File', 'Class', 'X', 'Y', 'H', 'W'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VegV8pLX06ln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_validation_data(VALIDATION_DIR,labels,val_notations, target_size=None):\n",
        "  \n",
        "  labels_set = set(labels)\n",
        "  label_dict = {}\n",
        "  for i in range(len(labels_set)):\n",
        "    label_dict[labels_set.pop()] = 0\n",
        " \n",
        "  SIZE = 64\n",
        "  CHANNEL = 3\n",
        "\n",
        "  images_val_list = []\n",
        "  labels_val_list = []\n",
        "\n",
        "  validation_counter = 0\n",
        "  for img_name in os.listdir(VALIDATION_DIR+\"images/\"):\n",
        "    img_path = os.path.join(VALIDATION_DIR+\"images/\"+img_name)\n",
        "    img_data = cv.imread(img_path)   \n",
        "    name_label = get_label(val_notations,img_name)\n",
        "    if name_label in label_dict.keys():  \n",
        "      label_dict[name_label] += 1\n",
        "      validation_counter+=1\n",
        "      if target_size:\n",
        "        frac = target_size/SIZE\n",
        "        img_data = cv.resize(img_data,None,fx=frac,fy=frac)\n",
        "      images_val_list.append(img_data)\n",
        "      labels_val_list.append(name_label)\n",
        "      if validation_counter%1000==0:\n",
        "        print(validation_counter)\n",
        "        print(label_dict)    \n",
        "      \n",
        "    \n",
        "  images_val = np.asarray(images_val_list)\n",
        "  labels_val = np.asarray(labels_val_list)\n",
        "  \n",
        "  print(validation_counter)\n",
        "  print(label_dict)\n",
        "  return images_val,labels_val\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdkhhTzv6TnC",
        "colab_type": "code",
        "outputId": "6d7a04b4-8508-4356-879b-5d91f4a9f97a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        }
      },
      "source": [
        "val_images, val_labels = load_validation_data(VALIDATION_DIR,labels,val_notations, 64)\n",
        "print(len(val_labels))\n",
        "\n",
        "permut = np.random.permutation(len(val_labels))\n",
        "testing_images = val_images[permut]\n",
        "testing_labels = val_labels[permut]\n",
        "\n",
        "\n",
        "#Encoding labels\n",
        "testing_labels_encoded = le.transform(testing_labels)\n",
        "nb_classes_val = len(le.classes_)\n",
        "\n",
        "X_test = testing_images\n",
        "\n",
        "#One Hot Encoding\n",
        "pre_Y_test = testing_labels_encoded\n",
        "Y_test = np_utils.to_categorical(pre_Y_test, nb_classes_val)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n",
            "{'n02132136': 8, 'n03902125': 4, 'n03770439': 7, 'n03400231': 3, 'n02403003': 4, 'n02814860': 3, 'n03617480': 4, 'n04486054': 14, 'n04311004': 8, 'n04074963': 7, 'n03891332': 2, 'n02509815': 10, 'n04285008': 3, 'n01784675': 6, 'n02190166': 5, 'n01774750': 6, 'n02948072': 7, 'n04560804': 4, 'n03355925': 3, 'n03255030': 4, 'n07615774': 6, 'n03544143': 3, 'n03042490': 5, 'n02841315': 3, 'n04456115': 6, 'n02793495': 1, 'n02795169': 4, 'n02977058': 5, 'n07753592': 5, 'n09193705': 2, 'n03179701': 3, 'n04376876': 9, 'n01770393': 4, 'n02281406': 5, 'n02321529': 3, 'n02906734': 6, 'n02999410': 6, 'n01983481': 5, 'n07747607': 4, 'n02106662': 3, 'n02085620': 5, 'n03992509': 6, 'n02669723': 6, 'n04251144': 7, 'n02231487': 4, 'n04487081': 4, 'n02963159': 4, 'n02481823': 9, 'n07873807': 2, 'n02094433': 6, 'n02437312': 4, 'n02099601': 1, 'n02988304': 5, 'n03201208': 7, 'n02058221': 3, 'n07583066': 6, 'n04070727': 5, 'n02699494': 4, 'n02410509': 6, 'n03393912': 9, 'n04532106': 5, 'n07715103': 4, 'n03404251': 2, 'n03837869': 2, 'n03763968': 4, 'n03854065': 8, 'n04067472': 6, 'n03089624': 4, 'n02002724': 5, 'n09256479': 3, 'n03796401': 9, 'n04149813': 8, 'n02802426': 4, 'n02791270': 3, 'n02788148': 2, 'n02056570': 2, 'n02927161': 1, 'n02395406': 6, 'n04398044': 5, 'n04328186': 3, 'n03977966': 5, 'n01882714': 5, 'n02950826': 5, 'n02730930': 4, 'n01768244': 8, 'n03388043': 3, 'n04008634': 6, 'n03085013': 5, 'n03250847': 2, 'n07695742': 6, 'n02808440': 6, 'n02268443': 7, 'n03814639': 3, 'n02206856': 6, 'n07920052': 4, 'n04133789': 5, 'n04146614': 1, 'n02074367': 2, 'n02099712': 6, 'n04399382': 3, 'n04501370': 5, 'n02233338': 5, 'n03980874': 8, 'n04099969': 3, 'n07720875': 6, 'n07768694': 4, 'n01917289': 7, 'n04371430': 8, 'n02837789': 3, 'n04540053': 5, 'n07749582': 6, 'n02917067': 7, 'n03670208': 6, 'n04532670': 4, 'n07875152': 4, 'n01984695': 5, 'n07871810': 4, 'n03599486': 4, 'n09428293': 10, 'n02129165': 8, 'n01698640': 7, 'n02123045': 6, 'n02666196': 0, 'n03930313': 7, 'n01945685': 3, 'n02113799': 1, 'n01443537': 7, 'n02892201': 5, 'n01855672': 5, 'n04356056': 6, 'n03126707': 7, 'n03447447': 7, 'n01950731': 3, 'n03026506': 8, 'n03976657': 6, 'n03424325': 3, 'n01641577': 3, 'n04254777': 2, 'n04597913': 5, 'n02123394': 4, 'n12267677': 8, 'n02504458': 8, 'n02226429': 3, 'n02423022': 6, 'n07614500': 6, 'n02843684': 6, 'n03637318': 3, 'n04596742': 8, 'n02279972': 3, 'n02909870': 4, 'n04417672': 3, 'n04023962': 7, 'n04366367': 9, 'n03983396': 7, 'n03804744': 5, 'n01629819': 5, 'n02124075': 4, 'n03706229': 4, 'n09246464': 4, 'n03444034': 4, 'n01944390': 5, 'n06596364': 3, 'n03584254': 4, 'n03733131': 3, 'n02486410': 6, 'n01742172': 3, 'n01774384': 10, 'n03838899': 6, 'n04265275': 5, 'n04507155': 5, 'n02823428': 7, 'n09332890': 8, 'n03649909': 6, 'n07711569': 7, 'n04465501': 9, 'n03970156': 11, 'n04259630': 4, 'n07579787': 5, 'n02125311': 9, 'n04118538': 3, 'n03937543': 3, 'n02883205': 6, 'n03014705': 4, 'n04179913': 3, 'n03662601': 4, 'n03100240': 4, 'n02480495': 5, 'n04562935': 9, 'n01910747': 4, 'n02415577': 5, 'n02165456': 3, 'n02236044': 4, 'n07734744': 7, 'n04275548': 4, 'n02364673': 3, 'n02815834': 3, 'n03160309': 3, 'n02769748': 3, 'n02814533': 6, 'n01644900': 3}\n",
            "2000\n",
            "{'n02132136': 11, 'n03902125': 10, 'n03770439': 11, 'n03400231': 11, 'n02403003': 7, 'n02814860': 7, 'n03617480': 14, 'n04486054': 16, 'n04311004': 13, 'n04074963': 11, 'n03891332': 12, 'n02509815': 15, 'n04285008': 9, 'n01784675': 15, 'n02190166': 10, 'n01774750': 9, 'n02948072': 8, 'n04560804': 8, 'n03355925': 6, 'n03255030': 6, 'n07615774': 15, 'n03544143': 8, 'n03042490': 11, 'n02841315': 9, 'n04456115': 14, 'n02793495': 4, 'n02795169': 7, 'n02977058': 11, 'n07753592': 11, 'n09193705': 8, 'n03179701': 8, 'n04376876': 13, 'n01770393': 9, 'n02281406': 10, 'n02321529': 12, 'n02906734': 10, 'n02999410': 11, 'n01983481': 8, 'n07747607': 8, 'n02106662': 9, 'n02085620': 7, 'n03992509': 10, 'n02669723': 12, 'n04251144': 16, 'n02231487': 11, 'n04487081': 7, 'n02963159': 8, 'n02481823': 16, 'n07873807': 8, 'n02094433': 11, 'n02437312': 9, 'n02099601': 6, 'n02988304': 11, 'n03201208': 15, 'n02058221': 7, 'n07583066': 12, 'n04070727': 7, 'n02699494': 6, 'n02410509': 9, 'n03393912': 15, 'n04532106': 8, 'n07715103': 9, 'n03404251': 9, 'n03837869': 5, 'n03763968': 7, 'n03854065': 14, 'n04067472': 13, 'n03089624': 5, 'n02002724': 7, 'n09256479': 4, 'n03796401': 12, 'n04149813': 9, 'n02802426': 9, 'n02791270': 7, 'n02788148': 4, 'n02056570': 9, 'n02927161': 4, 'n02395406': 13, 'n04398044': 10, 'n04328186': 10, 'n03977966': 9, 'n01882714': 7, 'n02950826': 12, 'n02730930': 10, 'n01768244': 9, 'n03388043': 7, 'n04008634': 10, 'n03085013': 11, 'n03250847': 9, 'n07695742': 9, 'n02808440': 6, 'n02268443': 13, 'n03814639': 6, 'n02206856': 11, 'n07920052': 7, 'n04133789': 8, 'n04146614': 8, 'n02074367': 5, 'n02099712': 13, 'n04399382': 10, 'n04501370': 9, 'n02233338': 7, 'n03980874': 15, 'n04099969': 10, 'n07720875': 8, 'n07768694': 10, 'n01917289': 13, 'n04371430': 13, 'n02837789': 6, 'n04540053': 10, 'n07749582': 14, 'n02917067': 11, 'n03670208': 11, 'n04532670': 14, 'n07875152': 6, 'n01984695': 12, 'n07871810': 9, 'n03599486': 11, 'n09428293': 15, 'n02129165': 10, 'n01698640': 9, 'n02123045': 6, 'n02666196': 5, 'n03930313': 9, 'n01945685': 4, 'n02113799': 9, 'n01443537': 18, 'n02892201': 12, 'n01855672': 8, 'n04356056': 9, 'n03126707': 10, 'n03447447': 13, 'n01950731': 11, 'n03026506': 12, 'n03976657': 12, 'n03424325': 12, 'n01641577': 7, 'n04254777': 5, 'n04597913': 12, 'n02123394': 10, 'n12267677': 11, 'n02504458': 16, 'n02226429': 12, 'n02423022': 13, 'n07614500': 10, 'n02843684': 10, 'n03637318': 9, 'n04596742': 14, 'n02279972': 8, 'n02909870': 10, 'n04417672': 9, 'n04023962': 14, 'n04366367': 14, 'n03983396': 10, 'n03804744': 11, 'n01629819': 12, 'n02124075': 9, 'n03706229': 11, 'n09246464': 6, 'n03444034': 13, 'n01944390': 13, 'n06596364': 7, 'n03584254': 9, 'n03733131': 12, 'n02486410': 9, 'n01742172': 9, 'n01774384': 14, 'n03838899': 9, 'n04265275': 11, 'n04507155': 8, 'n02823428': 14, 'n09332890': 16, 'n03649909': 13, 'n07711569': 12, 'n04465501': 15, 'n03970156': 14, 'n04259630': 10, 'n07579787': 12, 'n02125311': 14, 'n04118538': 11, 'n03937543': 6, 'n02883205': 9, 'n03014705': 7, 'n04179913': 8, 'n03662601': 11, 'n03100240': 7, 'n02480495': 8, 'n04562935': 10, 'n01910747': 8, 'n02415577': 8, 'n02165456': 10, 'n02236044': 7, 'n07734744': 12, 'n04275548': 12, 'n02364673': 8, 'n02815834': 9, 'n03160309': 12, 'n02769748': 8, 'n02814533': 15, 'n01644900': 8}\n",
            "3000\n",
            "{'n02132136': 16, 'n03902125': 15, 'n03770439': 17, 'n03400231': 14, 'n02403003': 16, 'n02814860': 13, 'n03617480': 16, 'n04486054': 22, 'n04311004': 16, 'n04074963': 14, 'n03891332': 16, 'n02509815': 21, 'n04285008': 16, 'n01784675': 21, 'n02190166': 14, 'n01774750': 13, 'n02948072': 13, 'n04560804': 11, 'n03355925': 9, 'n03255030': 11, 'n07615774': 21, 'n03544143': 14, 'n03042490': 16, 'n02841315': 13, 'n04456115': 21, 'n02793495': 14, 'n02795169': 17, 'n02977058': 16, 'n07753592': 18, 'n09193705': 10, 'n03179701': 15, 'n04376876': 17, 'n01770393': 13, 'n02281406': 17, 'n02321529': 17, 'n02906734': 17, 'n02999410': 13, 'n01983481': 12, 'n07747607': 14, 'n02106662': 15, 'n02085620': 12, 'n03992509': 11, 'n02669723': 17, 'n04251144': 21, 'n02231487': 13, 'n04487081': 11, 'n02963159': 11, 'n02481823': 23, 'n07873807': 13, 'n02094433': 15, 'n02437312': 17, 'n02099601': 9, 'n02988304': 17, 'n03201208': 18, 'n02058221': 10, 'n07583066': 19, 'n04070727': 16, 'n02699494': 9, 'n02410509': 12, 'n03393912': 18, 'n04532106': 13, 'n07715103': 14, 'n03404251': 16, 'n03837869': 11, 'n03763968': 12, 'n03854065': 17, 'n04067472': 20, 'n03089624': 12, 'n02002724': 12, 'n09256479': 7, 'n03796401': 17, 'n04149813': 14, 'n02802426': 12, 'n02791270': 10, 'n02788148': 9, 'n02056570': 14, 'n02927161': 8, 'n02395406': 16, 'n04398044': 14, 'n04328186': 12, 'n03977966': 15, 'n01882714': 15, 'n02950826': 15, 'n02730930': 15, 'n01768244': 16, 'n03388043': 14, 'n04008634': 16, 'n03085013': 18, 'n03250847': 13, 'n07695742': 17, 'n02808440': 9, 'n02268443': 17, 'n03814639': 11, 'n02206856': 13, 'n07920052': 12, 'n04133789': 14, 'n04146614': 13, 'n02074367': 12, 'n02099712': 18, 'n04399382': 11, 'n04501370': 14, 'n02233338': 14, 'n03980874': 19, 'n04099969': 15, 'n07720875': 12, 'n07768694': 17, 'n01917289': 18, 'n04371430': 19, 'n02837789': 13, 'n04540053': 13, 'n07749582': 19, 'n02917067': 13, 'n03670208': 13, 'n04532670': 22, 'n07875152': 9, 'n01984695': 23, 'n07871810': 14, 'n03599486': 16, 'n09428293': 18, 'n02129165': 19, 'n01698640': 15, 'n02123045': 8, 'n02666196': 9, 'n03930313': 13, 'n01945685': 11, 'n02113799': 14, 'n01443537': 27, 'n02892201': 15, 'n01855672': 12, 'n04356056': 13, 'n03126707': 16, 'n03447447': 21, 'n01950731': 18, 'n03026506': 14, 'n03976657': 17, 'n03424325': 16, 'n01641577': 15, 'n04254777': 12, 'n04597913': 20, 'n02123394': 14, 'n12267677': 14, 'n02504458': 20, 'n02226429': 14, 'n02423022': 19, 'n07614500': 18, 'n02843684': 16, 'n03637318': 17, 'n04596742': 23, 'n02279972': 14, 'n02909870': 16, 'n04417672': 13, 'n04023962': 21, 'n04366367': 21, 'n03983396': 16, 'n03804744': 18, 'n01629819': 20, 'n02124075': 14, 'n03706229': 17, 'n09246464': 8, 'n03444034': 14, 'n01944390': 15, 'n06596364': 13, 'n03584254': 10, 'n03733131': 19, 'n02486410': 14, 'n01742172': 14, 'n01774384': 18, 'n03838899': 12, 'n04265275': 15, 'n04507155': 13, 'n02823428': 19, 'n09332890': 20, 'n03649909': 20, 'n07711569': 20, 'n04465501': 17, 'n03970156': 18, 'n04259630': 18, 'n07579787': 16, 'n02125311': 18, 'n04118538': 15, 'n03937543': 12, 'n02883205': 14, 'n03014705': 15, 'n04179913': 13, 'n03662601': 19, 'n03100240': 12, 'n02480495': 13, 'n04562935': 12, 'n01910747': 14, 'n02415577': 13, 'n02165456': 11, 'n02236044': 11, 'n07734744': 18, 'n04275548': 17, 'n02364673': 12, 'n02815834': 9, 'n03160309': 16, 'n02769748': 12, 'n02814533': 16, 'n01644900': 14}\n",
            "4000\n",
            "{'n02132136': 21, 'n03902125': 19, 'n03770439': 22, 'n03400231': 20, 'n02403003': 23, 'n02814860': 20, 'n03617480': 23, 'n04486054': 26, 'n04311004': 20, 'n04074963': 19, 'n03891332': 19, 'n02509815': 26, 'n04285008': 22, 'n01784675': 28, 'n02190166': 19, 'n01774750': 21, 'n02948072': 22, 'n04560804': 16, 'n03355925': 16, 'n03255030': 15, 'n07615774': 26, 'n03544143': 20, 'n03042490': 19, 'n02841315': 17, 'n04456115': 26, 'n02793495': 19, 'n02795169': 20, 'n02977058': 21, 'n07753592': 22, 'n09193705': 18, 'n03179701': 24, 'n04376876': 21, 'n01770393': 18, 'n02281406': 21, 'n02321529': 20, 'n02906734': 19, 'n02999410': 17, 'n01983481': 17, 'n07747607': 17, 'n02106662': 18, 'n02085620': 20, 'n03992509': 14, 'n02669723': 21, 'n04251144': 26, 'n02231487': 19, 'n04487081': 15, 'n02963159': 16, 'n02481823': 27, 'n07873807': 17, 'n02094433': 22, 'n02437312': 21, 'n02099601': 14, 'n02988304': 20, 'n03201208': 22, 'n02058221': 18, 'n07583066': 26, 'n04070727': 19, 'n02699494': 14, 'n02410509': 12, 'n03393912': 19, 'n04532106': 18, 'n07715103': 17, 'n03404251': 21, 'n03837869': 16, 'n03763968': 19, 'n03854065': 19, 'n04067472': 27, 'n03089624': 19, 'n02002724': 16, 'n09256479': 14, 'n03796401': 21, 'n04149813': 20, 'n02802426': 21, 'n02791270': 20, 'n02788148': 13, 'n02056570': 21, 'n02927161': 12, 'n02395406': 17, 'n04398044': 18, 'n04328186': 16, 'n03977966': 20, 'n01882714': 17, 'n02950826': 20, 'n02730930': 18, 'n01768244': 17, 'n03388043': 21, 'n04008634': 20, 'n03085013': 22, 'n03250847': 18, 'n07695742': 21, 'n02808440': 14, 'n02268443': 23, 'n03814639': 15, 'n02206856': 17, 'n07920052': 13, 'n04133789': 17, 'n04146614': 21, 'n02074367': 18, 'n02099712': 22, 'n04399382': 18, 'n04501370': 17, 'n02233338': 20, 'n03980874': 22, 'n04099969': 23, 'n07720875': 15, 'n07768694': 18, 'n01917289': 25, 'n04371430': 23, 'n02837789': 20, 'n04540053': 17, 'n07749582': 25, 'n02917067': 18, 'n03670208': 21, 'n04532670': 25, 'n07875152': 17, 'n01984695': 25, 'n07871810': 20, 'n03599486': 21, 'n09428293': 22, 'n02129165': 21, 'n01698640': 23, 'n02123045': 19, 'n02666196': 17, 'n03930313': 22, 'n01945685': 20, 'n02113799': 19, 'n01443537': 30, 'n02892201': 22, 'n01855672': 14, 'n04356056': 17, 'n03126707': 21, 'n03447447': 25, 'n01950731': 25, 'n03026506': 21, 'n03976657': 21, 'n03424325': 22, 'n01641577': 20, 'n04254777': 20, 'n04597913': 23, 'n02123394': 18, 'n12267677': 18, 'n02504458': 24, 'n02226429': 21, 'n02423022': 24, 'n07614500': 25, 'n02843684': 22, 'n03637318': 18, 'n04596742': 29, 'n02279972': 18, 'n02909870': 22, 'n04417672': 19, 'n04023962': 29, 'n04366367': 24, 'n03983396': 22, 'n03804744': 23, 'n01629819': 22, 'n02124075': 15, 'n03706229': 21, 'n09246464': 13, 'n03444034': 23, 'n01944390': 19, 'n06596364': 19, 'n03584254': 14, 'n03733131': 20, 'n02486410': 15, 'n01742172': 20, 'n01774384': 22, 'n03838899': 18, 'n04265275': 20, 'n04507155': 18, 'n02823428': 21, 'n09332890': 23, 'n03649909': 26, 'n07711569': 25, 'n04465501': 23, 'n03970156': 23, 'n04259630': 20, 'n07579787': 20, 'n02125311': 24, 'n04118538': 18, 'n03937543': 20, 'n02883205': 21, 'n03014705': 19, 'n04179913': 16, 'n03662601': 26, 'n03100240': 15, 'n02480495': 20, 'n04562935': 16, 'n01910747': 16, 'n02415577': 24, 'n02165456': 17, 'n02236044': 21, 'n07734744': 27, 'n04275548': 25, 'n02364673': 17, 'n02815834': 15, 'n03160309': 20, 'n02769748': 16, 'n02814533': 20, 'n01644900': 19}\n",
            "5000\n",
            "{'n02132136': 26, 'n03902125': 21, 'n03770439': 26, 'n03400231': 26, 'n02403003': 26, 'n02814860': 26, 'n03617480': 26, 'n04486054': 30, 'n04311004': 25, 'n04074963': 21, 'n03891332': 26, 'n02509815': 33, 'n04285008': 29, 'n01784675': 32, 'n02190166': 25, 'n01774750': 27, 'n02948072': 25, 'n04560804': 22, 'n03355925': 24, 'n03255030': 23, 'n07615774': 30, 'n03544143': 25, 'n03042490': 22, 'n02841315': 23, 'n04456115': 31, 'n02793495': 22, 'n02795169': 26, 'n02977058': 25, 'n07753592': 27, 'n09193705': 23, 'n03179701': 28, 'n04376876': 24, 'n01770393': 21, 'n02281406': 27, 'n02321529': 26, 'n02906734': 23, 'n02999410': 22, 'n01983481': 23, 'n07747607': 21, 'n02106662': 23, 'n02085620': 24, 'n03992509': 24, 'n02669723': 24, 'n04251144': 28, 'n02231487': 24, 'n04487081': 22, 'n02963159': 23, 'n02481823': 31, 'n07873807': 22, 'n02094433': 29, 'n02437312': 30, 'n02099601': 24, 'n02988304': 28, 'n03201208': 23, 'n02058221': 20, 'n07583066': 29, 'n04070727': 24, 'n02699494': 22, 'n02410509': 19, 'n03393912': 22, 'n04532106': 22, 'n07715103': 22, 'n03404251': 26, 'n03837869': 21, 'n03763968': 22, 'n03854065': 25, 'n04067472': 32, 'n03089624': 26, 'n02002724': 20, 'n09256479': 16, 'n03796401': 28, 'n04149813': 26, 'n02802426': 26, 'n02791270': 26, 'n02788148': 23, 'n02056570': 24, 'n02927161': 25, 'n02395406': 20, 'n04398044': 23, 'n04328186': 20, 'n03977966': 28, 'n01882714': 23, 'n02950826': 24, 'n02730930': 25, 'n01768244': 21, 'n03388043': 24, 'n04008634': 27, 'n03085013': 27, 'n03250847': 23, 'n07695742': 29, 'n02808440': 19, 'n02268443': 25, 'n03814639': 21, 'n02206856': 22, 'n07920052': 17, 'n04133789': 23, 'n04146614': 30, 'n02074367': 23, 'n02099712': 26, 'n04399382': 20, 'n04501370': 20, 'n02233338': 25, 'n03980874': 29, 'n04099969': 29, 'n07720875': 23, 'n07768694': 23, 'n01917289': 27, 'n04371430': 30, 'n02837789': 25, 'n04540053': 22, 'n07749582': 28, 'n02917067': 22, 'n03670208': 24, 'n04532670': 28, 'n07875152': 20, 'n01984695': 29, 'n07871810': 21, 'n03599486': 28, 'n09428293': 28, 'n02129165': 24, 'n01698640': 27, 'n02123045': 25, 'n02666196': 23, 'n03930313': 26, 'n01945685': 28, 'n02113799': 23, 'n01443537': 35, 'n02892201': 27, 'n01855672': 17, 'n04356056': 22, 'n03126707': 25, 'n03447447': 29, 'n01950731': 29, 'n03026506': 25, 'n03976657': 25, 'n03424325': 23, 'n01641577': 24, 'n04254777': 27, 'n04597913': 28, 'n02123394': 28, 'n12267677': 24, 'n02504458': 31, 'n02226429': 23, 'n02423022': 30, 'n07614500': 27, 'n02843684': 25, 'n03637318': 24, 'n04596742': 35, 'n02279972': 24, 'n02909870': 27, 'n04417672': 23, 'n04023962': 32, 'n04366367': 29, 'n03983396': 25, 'n03804744': 29, 'n01629819': 25, 'n02124075': 21, 'n03706229': 24, 'n09246464': 20, 'n03444034': 31, 'n01944390': 25, 'n06596364': 26, 'n03584254': 21, 'n03733131': 27, 'n02486410': 20, 'n01742172': 24, 'n01774384': 26, 'n03838899': 26, 'n04265275': 26, 'n04507155': 22, 'n02823428': 28, 'n09332890': 30, 'n03649909': 29, 'n07711569': 31, 'n04465501': 27, 'n03970156': 29, 'n04259630': 28, 'n07579787': 24, 'n02125311': 25, 'n04118538': 20, 'n03937543': 25, 'n02883205': 24, 'n03014705': 21, 'n04179913': 20, 'n03662601': 30, 'n03100240': 21, 'n02480495': 25, 'n04562935': 22, 'n01910747': 21, 'n02415577': 27, 'n02165456': 23, 'n02236044': 25, 'n07734744': 30, 'n04275548': 29, 'n02364673': 25, 'n02815834': 19, 'n03160309': 23, 'n02769748': 27, 'n02814533': 24, 'n01644900': 22}\n",
            "6000\n",
            "{'n02132136': 29, 'n03902125': 24, 'n03770439': 29, 'n03400231': 29, 'n02403003': 33, 'n02814860': 30, 'n03617480': 30, 'n04486054': 35, 'n04311004': 28, 'n04074963': 28, 'n03891332': 32, 'n02509815': 38, 'n04285008': 36, 'n01784675': 33, 'n02190166': 29, 'n01774750': 30, 'n02948072': 27, 'n04560804': 28, 'n03355925': 30, 'n03255030': 29, 'n07615774': 37, 'n03544143': 28, 'n03042490': 28, 'n02841315': 25, 'n04456115': 33, 'n02793495': 27, 'n02795169': 31, 'n02977058': 29, 'n07753592': 30, 'n09193705': 30, 'n03179701': 31, 'n04376876': 28, 'n01770393': 25, 'n02281406': 32, 'n02321529': 31, 'n02906734': 27, 'n02999410': 27, 'n01983481': 31, 'n07747607': 28, 'n02106662': 30, 'n02085620': 30, 'n03992509': 31, 'n02669723': 32, 'n04251144': 34, 'n02231487': 28, 'n04487081': 25, 'n02963159': 31, 'n02481823': 35, 'n07873807': 31, 'n02094433': 32, 'n02437312': 34, 'n02099601': 30, 'n02988304': 33, 'n03201208': 31, 'n02058221': 30, 'n07583066': 32, 'n04070727': 31, 'n02699494': 29, 'n02410509': 28, 'n03393912': 28, 'n04532106': 30, 'n07715103': 26, 'n03404251': 31, 'n03837869': 26, 'n03763968': 28, 'n03854065': 31, 'n04067472': 37, 'n03089624': 30, 'n02002724': 23, 'n09256479': 20, 'n03796401': 30, 'n04149813': 30, 'n02802426': 33, 'n02791270': 30, 'n02788148': 34, 'n02056570': 28, 'n02927161': 27, 'n02395406': 24, 'n04398044': 33, 'n04328186': 25, 'n03977966': 34, 'n01882714': 30, 'n02950826': 28, 'n02730930': 33, 'n01768244': 28, 'n03388043': 29, 'n04008634': 33, 'n03085013': 30, 'n03250847': 29, 'n07695742': 35, 'n02808440': 24, 'n02268443': 29, 'n03814639': 23, 'n02206856': 27, 'n07920052': 22, 'n04133789': 32, 'n04146614': 32, 'n02074367': 29, 'n02099712': 32, 'n04399382': 25, 'n04501370': 22, 'n02233338': 30, 'n03980874': 36, 'n04099969': 32, 'n07720875': 29, 'n07768694': 30, 'n01917289': 33, 'n04371430': 34, 'n02837789': 26, 'n04540053': 27, 'n07749582': 32, 'n02917067': 28, 'n03670208': 31, 'n04532670': 32, 'n07875152': 25, 'n01984695': 35, 'n07871810': 25, 'n03599486': 29, 'n09428293': 34, 'n02129165': 29, 'n01698640': 28, 'n02123045': 33, 'n02666196': 27, 'n03930313': 30, 'n01945685': 34, 'n02113799': 31, 'n01443537': 37, 'n02892201': 30, 'n01855672': 24, 'n04356056': 26, 'n03126707': 33, 'n03447447': 35, 'n01950731': 32, 'n03026506': 29, 'n03976657': 31, 'n03424325': 28, 'n01641577': 29, 'n04254777': 34, 'n04597913': 32, 'n02123394': 33, 'n12267677': 27, 'n02504458': 38, 'n02226429': 27, 'n02423022': 34, 'n07614500': 33, 'n02843684': 29, 'n03637318': 30, 'n04596742': 37, 'n02279972': 27, 'n02909870': 33, 'n04417672': 35, 'n04023962': 37, 'n04366367': 35, 'n03983396': 29, 'n03804744': 32, 'n01629819': 30, 'n02124075': 29, 'n03706229': 28, 'n09246464': 27, 'n03444034': 35, 'n01944390': 33, 'n06596364': 29, 'n03584254': 26, 'n03733131': 31, 'n02486410': 28, 'n01742172': 28, 'n01774384': 31, 'n03838899': 32, 'n04265275': 29, 'n04507155': 29, 'n02823428': 36, 'n09332890': 33, 'n03649909': 31, 'n07711569': 33, 'n04465501': 29, 'n03970156': 35, 'n04259630': 30, 'n07579787': 27, 'n02125311': 33, 'n04118538': 28, 'n03937543': 27, 'n02883205': 26, 'n03014705': 26, 'n04179913': 27, 'n03662601': 33, 'n03100240': 25, 'n02480495': 29, 'n04562935': 34, 'n01910747': 26, 'n02415577': 29, 'n02165456': 29, 'n02236044': 26, 'n07734744': 34, 'n04275548': 35, 'n02364673': 28, 'n02815834': 22, 'n03160309': 33, 'n02769748': 31, 'n02814533': 26, 'n01644900': 26}\n",
            "7000\n",
            "{'n02132136': 34, 'n03902125': 31, 'n03770439': 32, 'n03400231': 38, 'n02403003': 36, 'n02814860': 32, 'n03617480': 37, 'n04486054': 39, 'n04311004': 36, 'n04074963': 37, 'n03891332': 35, 'n02509815': 43, 'n04285008': 38, 'n01784675': 36, 'n02190166': 36, 'n01774750': 33, 'n02948072': 36, 'n04560804': 34, 'n03355925': 35, 'n03255030': 37, 'n07615774': 40, 'n03544143': 34, 'n03042490': 37, 'n02841315': 30, 'n04456115': 36, 'n02793495': 29, 'n02795169': 35, 'n02977058': 31, 'n07753592': 36, 'n09193705': 34, 'n03179701': 37, 'n04376876': 32, 'n01770393': 34, 'n02281406': 39, 'n02321529': 38, 'n02906734': 30, 'n02999410': 33, 'n01983481': 32, 'n07747607': 36, 'n02106662': 35, 'n02085620': 34, 'n03992509': 37, 'n02669723': 36, 'n04251144': 36, 'n02231487': 34, 'n04487081': 31, 'n02963159': 37, 'n02481823': 37, 'n07873807': 36, 'n02094433': 35, 'n02437312': 39, 'n02099601': 34, 'n02988304': 36, 'n03201208': 36, 'n02058221': 33, 'n07583066': 34, 'n04070727': 39, 'n02699494': 36, 'n02410509': 35, 'n03393912': 34, 'n04532106': 35, 'n07715103': 37, 'n03404251': 35, 'n03837869': 31, 'n03763968': 34, 'n03854065': 36, 'n04067472': 43, 'n03089624': 35, 'n02002724': 33, 'n09256479': 28, 'n03796401': 34, 'n04149813': 36, 'n02802426': 34, 'n02791270': 35, 'n02788148': 37, 'n02056570': 33, 'n02927161': 32, 'n02395406': 31, 'n04398044': 37, 'n04328186': 30, 'n03977966': 38, 'n01882714': 36, 'n02950826': 30, 'n02730930': 38, 'n01768244': 33, 'n03388043': 35, 'n04008634': 38, 'n03085013': 34, 'n03250847': 34, 'n07695742': 37, 'n02808440': 33, 'n02268443': 35, 'n03814639': 24, 'n02206856': 31, 'n07920052': 30, 'n04133789': 36, 'n04146614': 36, 'n02074367': 32, 'n02099712': 34, 'n04399382': 30, 'n04501370': 30, 'n02233338': 35, 'n03980874': 37, 'n04099969': 34, 'n07720875': 37, 'n07768694': 34, 'n01917289': 37, 'n04371430': 38, 'n02837789': 31, 'n04540053': 39, 'n07749582': 37, 'n02917067': 34, 'n03670208': 35, 'n04532670': 37, 'n07875152': 30, 'n01984695': 37, 'n07871810': 28, 'n03599486': 33, 'n09428293': 35, 'n02129165': 36, 'n01698640': 31, 'n02123045': 41, 'n02666196': 31, 'n03930313': 36, 'n01945685': 39, 'n02113799': 33, 'n01443537': 41, 'n02892201': 34, 'n01855672': 28, 'n04356056': 32, 'n03126707': 38, 'n03447447': 38, 'n01950731': 38, 'n03026506': 33, 'n03976657': 37, 'n03424325': 30, 'n01641577': 35, 'n04254777': 35, 'n04597913': 34, 'n02123394': 38, 'n12267677': 37, 'n02504458': 42, 'n02226429': 31, 'n02423022': 37, 'n07614500': 37, 'n02843684': 34, 'n03637318': 37, 'n04596742': 41, 'n02279972': 33, 'n02909870': 35, 'n04417672': 38, 'n04023962': 41, 'n04366367': 39, 'n03983396': 35, 'n03804744': 36, 'n01629819': 34, 'n02124075': 34, 'n03706229': 35, 'n09246464': 38, 'n03444034': 39, 'n01944390': 36, 'n06596364': 34, 'n03584254': 32, 'n03733131': 35, 'n02486410': 31, 'n01742172': 33, 'n01774384': 38, 'n03838899': 36, 'n04265275': 32, 'n04507155': 34, 'n02823428': 40, 'n09332890': 40, 'n03649909': 37, 'n07711569': 38, 'n04465501': 33, 'n03970156': 40, 'n04259630': 35, 'n07579787': 35, 'n02125311': 38, 'n04118538': 41, 'n03937543': 33, 'n02883205': 31, 'n03014705': 31, 'n04179913': 32, 'n03662601': 37, 'n03100240': 35, 'n02480495': 32, 'n04562935': 39, 'n01910747': 32, 'n02415577': 34, 'n02165456': 35, 'n02236044': 29, 'n07734744': 38, 'n04275548': 38, 'n02364673': 34, 'n02815834': 30, 'n03160309': 36, 'n02769748': 35, 'n02814533': 35, 'n01644900': 35}\n",
            "8000\n",
            "{'n02132136': 39, 'n03902125': 40, 'n03770439': 39, 'n03400231': 43, 'n02403003': 40, 'n02814860': 39, 'n03617480': 45, 'n04486054': 44, 'n04311004': 38, 'n04074963': 41, 'n03891332': 41, 'n02509815': 45, 'n04285008': 41, 'n01784675': 38, 'n02190166': 41, 'n01774750': 40, 'n02948072': 41, 'n04560804': 39, 'n03355925': 40, 'n03255030': 38, 'n07615774': 44, 'n03544143': 41, 'n03042490': 44, 'n02841315': 36, 'n04456115': 44, 'n02793495': 34, 'n02795169': 40, 'n02977058': 36, 'n07753592': 39, 'n09193705': 39, 'n03179701': 39, 'n04376876': 42, 'n01770393': 36, 'n02281406': 43, 'n02321529': 40, 'n02906734': 40, 'n02999410': 43, 'n01983481': 35, 'n07747607': 41, 'n02106662': 39, 'n02085620': 44, 'n03992509': 40, 'n02669723': 41, 'n04251144': 43, 'n02231487': 42, 'n04487081': 37, 'n02963159': 38, 'n02481823': 42, 'n07873807': 38, 'n02094433': 40, 'n02437312': 42, 'n02099601': 40, 'n02988304': 42, 'n03201208': 44, 'n02058221': 41, 'n07583066': 38, 'n04070727': 43, 'n02699494': 41, 'n02410509': 39, 'n03393912': 41, 'n04532106': 41, 'n07715103': 40, 'n03404251': 41, 'n03837869': 39, 'n03763968': 36, 'n03854065': 40, 'n04067472': 44, 'n03089624': 38, 'n02002724': 37, 'n09256479': 39, 'n03796401': 37, 'n04149813': 42, 'n02802426': 38, 'n02791270': 40, 'n02788148': 40, 'n02056570': 38, 'n02927161': 41, 'n02395406': 36, 'n04398044': 39, 'n04328186': 37, 'n03977966': 41, 'n01882714': 40, 'n02950826': 39, 'n02730930': 41, 'n01768244': 38, 'n03388043': 36, 'n04008634': 42, 'n03085013': 42, 'n03250847': 37, 'n07695742': 40, 'n02808440': 34, 'n02268443': 42, 'n03814639': 31, 'n02206856': 36, 'n07920052': 33, 'n04133789': 43, 'n04146614': 40, 'n02074367': 36, 'n02099712': 37, 'n04399382': 39, 'n04501370': 36, 'n02233338': 43, 'n03980874': 44, 'n04099969': 38, 'n07720875': 41, 'n07768694': 37, 'n01917289': 41, 'n04371430': 40, 'n02837789': 36, 'n04540053': 39, 'n07749582': 45, 'n02917067': 40, 'n03670208': 42, 'n04532670': 42, 'n07875152': 38, 'n01984695': 41, 'n07871810': 39, 'n03599486': 38, 'n09428293': 39, 'n02129165': 41, 'n01698640': 37, 'n02123045': 45, 'n02666196': 40, 'n03930313': 40, 'n01945685': 43, 'n02113799': 37, 'n01443537': 42, 'n02892201': 41, 'n01855672': 33, 'n04356056': 40, 'n03126707': 40, 'n03447447': 42, 'n01950731': 41, 'n03026506': 43, 'n03976657': 44, 'n03424325': 35, 'n01641577': 38, 'n04254777': 42, 'n04597913': 39, 'n02123394': 45, 'n12267677': 41, 'n02504458': 44, 'n02226429': 33, 'n02423022': 40, 'n07614500': 41, 'n02843684': 39, 'n03637318': 43, 'n04596742': 45, 'n02279972': 37, 'n02909870': 38, 'n04417672': 43, 'n04023962': 45, 'n04366367': 42, 'n03983396': 42, 'n03804744': 40, 'n01629819': 38, 'n02124075': 36, 'n03706229': 40, 'n09246464': 45, 'n03444034': 44, 'n01944390': 39, 'n06596364': 38, 'n03584254': 35, 'n03733131': 40, 'n02486410': 41, 'n01742172': 38, 'n01774384': 43, 'n03838899': 42, 'n04265275': 39, 'n04507155': 40, 'n02823428': 43, 'n09332890': 43, 'n03649909': 40, 'n07711569': 40, 'n04465501': 39, 'n03970156': 43, 'n04259630': 39, 'n07579787': 40, 'n02125311': 43, 'n04118538': 45, 'n03937543': 39, 'n02883205': 38, 'n03014705': 38, 'n04179913': 35, 'n03662601': 43, 'n03100240': 40, 'n02480495': 39, 'n04562935': 43, 'n01910747': 40, 'n02415577': 40, 'n02165456': 38, 'n02236044': 35, 'n07734744': 43, 'n04275548': 44, 'n02364673': 40, 'n02815834': 37, 'n03160309': 45, 'n02769748': 41, 'n02814533': 38, 'n01644900': 38}\n",
            "9000\n",
            "{'n02132136': 43, 'n03902125': 45, 'n03770439': 45, 'n03400231': 46, 'n02403003': 44, 'n02814860': 44, 'n03617480': 46, 'n04486054': 45, 'n04311004': 41, 'n04074963': 47, 'n03891332': 45, 'n02509815': 46, 'n04285008': 46, 'n01784675': 46, 'n02190166': 46, 'n01774750': 45, 'n02948072': 43, 'n04560804': 45, 'n03355925': 46, 'n03255030': 44, 'n07615774': 48, 'n03544143': 46, 'n03042490': 47, 'n02841315': 43, 'n04456115': 44, 'n02793495': 42, 'n02795169': 45, 'n02977058': 43, 'n07753592': 44, 'n09193705': 46, 'n03179701': 44, 'n04376876': 47, 'n01770393': 46, 'n02281406': 47, 'n02321529': 44, 'n02906734': 46, 'n02999410': 47, 'n01983481': 44, 'n07747607': 46, 'n02106662': 44, 'n02085620': 46, 'n03992509': 42, 'n02669723': 44, 'n04251144': 49, 'n02231487': 47, 'n04487081': 42, 'n02963159': 45, 'n02481823': 47, 'n07873807': 41, 'n02094433': 44, 'n02437312': 43, 'n02099601': 46, 'n02988304': 46, 'n03201208': 47, 'n02058221': 45, 'n07583066': 45, 'n04070727': 46, 'n02699494': 44, 'n02410509': 45, 'n03393912': 43, 'n04532106': 45, 'n07715103': 44, 'n03404251': 46, 'n03837869': 43, 'n03763968': 39, 'n03854065': 44, 'n04067472': 45, 'n03089624': 43, 'n02002724': 45, 'n09256479': 45, 'n03796401': 44, 'n04149813': 46, 'n02802426': 45, 'n02791270': 45, 'n02788148': 46, 'n02056570': 44, 'n02927161': 46, 'n02395406': 45, 'n04398044': 43, 'n04328186': 45, 'n03977966': 47, 'n01882714': 47, 'n02950826': 43, 'n02730930': 47, 'n01768244': 46, 'n03388043': 45, 'n04008634': 46, 'n03085013': 46, 'n03250847': 46, 'n07695742': 46, 'n02808440': 45, 'n02268443': 48, 'n03814639': 37, 'n02206856': 42, 'n07920052': 42, 'n04133789': 45, 'n04146614': 46, 'n02074367': 41, 'n02099712': 43, 'n04399382': 46, 'n04501370': 43, 'n02233338': 47, 'n03980874': 47, 'n04099969': 45, 'n07720875': 43, 'n07768694': 44, 'n01917289': 46, 'n04371430': 46, 'n02837789': 45, 'n04540053': 43, 'n07749582': 50, 'n02917067': 47, 'n03670208': 44, 'n04532670': 47, 'n07875152': 42, 'n01984695': 47, 'n07871810': 46, 'n03599486': 45, 'n09428293': 43, 'n02129165': 46, 'n01698640': 42, 'n02123045': 49, 'n02666196': 45, 'n03930313': 47, 'n01945685': 47, 'n02113799': 42, 'n01443537': 46, 'n02892201': 48, 'n01855672': 40, 'n04356056': 47, 'n03126707': 46, 'n03447447': 44, 'n01950731': 46, 'n03026506': 47, 'n03976657': 47, 'n03424325': 43, 'n01641577': 43, 'n04254777': 45, 'n04597913': 40, 'n02123394': 47, 'n12267677': 47, 'n02504458': 47, 'n02226429': 46, 'n02423022': 46, 'n07614500': 46, 'n02843684': 40, 'n03637318': 47, 'n04596742': 48, 'n02279972': 43, 'n02909870': 46, 'n04417672': 46, 'n04023962': 48, 'n04366367': 48, 'n03983396': 47, 'n03804744': 44, 'n01629819': 42, 'n02124075': 42, 'n03706229': 46, 'n09246464': 47, 'n03444034': 48, 'n01944390': 47, 'n06596364': 45, 'n03584254': 46, 'n03733131': 43, 'n02486410': 47, 'n01742172': 46, 'n01774384': 45, 'n03838899': 47, 'n04265275': 47, 'n04507155': 47, 'n02823428': 47, 'n09332890': 46, 'n03649909': 45, 'n07711569': 43, 'n04465501': 44, 'n03970156': 47, 'n04259630': 42, 'n07579787': 44, 'n02125311': 46, 'n04118538': 47, 'n03937543': 44, 'n02883205': 44, 'n03014705': 46, 'n04179913': 44, 'n03662601': 46, 'n03100240': 48, 'n02480495': 43, 'n04562935': 47, 'n01910747': 43, 'n02415577': 46, 'n02165456': 42, 'n02236044': 40, 'n07734744': 45, 'n04275548': 48, 'n02364673': 44, 'n02815834': 43, 'n03160309': 46, 'n02769748': 44, 'n02814533': 42, 'n01644900': 43}\n",
            "10000\n",
            "{'n02132136': 50, 'n03902125': 50, 'n03770439': 50, 'n03400231': 50, 'n02403003': 50, 'n02814860': 50, 'n03617480': 50, 'n04486054': 50, 'n04311004': 50, 'n04074963': 50, 'n03891332': 50, 'n02509815': 50, 'n04285008': 50, 'n01784675': 50, 'n02190166': 50, 'n01774750': 50, 'n02948072': 50, 'n04560804': 50, 'n03355925': 50, 'n03255030': 50, 'n07615774': 50, 'n03544143': 50, 'n03042490': 50, 'n02841315': 50, 'n04456115': 50, 'n02793495': 50, 'n02795169': 50, 'n02977058': 50, 'n07753592': 50, 'n09193705': 50, 'n03179701': 50, 'n04376876': 50, 'n01770393': 50, 'n02281406': 50, 'n02321529': 50, 'n02906734': 50, 'n02999410': 50, 'n01983481': 50, 'n07747607': 50, 'n02106662': 50, 'n02085620': 50, 'n03992509': 50, 'n02669723': 50, 'n04251144': 50, 'n02231487': 50, 'n04487081': 50, 'n02963159': 50, 'n02481823': 50, 'n07873807': 50, 'n02094433': 50, 'n02437312': 50, 'n02099601': 50, 'n02988304': 50, 'n03201208': 50, 'n02058221': 50, 'n07583066': 50, 'n04070727': 50, 'n02699494': 50, 'n02410509': 50, 'n03393912': 50, 'n04532106': 50, 'n07715103': 50, 'n03404251': 50, 'n03837869': 50, 'n03763968': 50, 'n03854065': 50, 'n04067472': 50, 'n03089624': 50, 'n02002724': 50, 'n09256479': 50, 'n03796401': 50, 'n04149813': 50, 'n02802426': 50, 'n02791270': 50, 'n02788148': 50, 'n02056570': 50, 'n02927161': 50, 'n02395406': 50, 'n04398044': 50, 'n04328186': 50, 'n03977966': 50, 'n01882714': 50, 'n02950826': 50, 'n02730930': 50, 'n01768244': 50, 'n03388043': 50, 'n04008634': 50, 'n03085013': 50, 'n03250847': 50, 'n07695742': 50, 'n02808440': 50, 'n02268443': 50, 'n03814639': 50, 'n02206856': 50, 'n07920052': 50, 'n04133789': 50, 'n04146614': 50, 'n02074367': 50, 'n02099712': 50, 'n04399382': 50, 'n04501370': 50, 'n02233338': 50, 'n03980874': 50, 'n04099969': 50, 'n07720875': 50, 'n07768694': 50, 'n01917289': 50, 'n04371430': 50, 'n02837789': 50, 'n04540053': 50, 'n07749582': 50, 'n02917067': 50, 'n03670208': 50, 'n04532670': 50, 'n07875152': 50, 'n01984695': 50, 'n07871810': 50, 'n03599486': 50, 'n09428293': 50, 'n02129165': 50, 'n01698640': 50, 'n02123045': 50, 'n02666196': 50, 'n03930313': 50, 'n01945685': 50, 'n02113799': 50, 'n01443537': 50, 'n02892201': 50, 'n01855672': 50, 'n04356056': 50, 'n03126707': 50, 'n03447447': 50, 'n01950731': 50, 'n03026506': 50, 'n03976657': 50, 'n03424325': 50, 'n01641577': 50, 'n04254777': 50, 'n04597913': 50, 'n02123394': 50, 'n12267677': 50, 'n02504458': 50, 'n02226429': 50, 'n02423022': 50, 'n07614500': 50, 'n02843684': 50, 'n03637318': 50, 'n04596742': 50, 'n02279972': 50, 'n02909870': 50, 'n04417672': 50, 'n04023962': 50, 'n04366367': 50, 'n03983396': 50, 'n03804744': 50, 'n01629819': 50, 'n02124075': 50, 'n03706229': 50, 'n09246464': 50, 'n03444034': 50, 'n01944390': 50, 'n06596364': 50, 'n03584254': 50, 'n03733131': 50, 'n02486410': 50, 'n01742172': 50, 'n01774384': 50, 'n03838899': 50, 'n04265275': 50, 'n04507155': 50, 'n02823428': 50, 'n09332890': 50, 'n03649909': 50, 'n07711569': 50, 'n04465501': 50, 'n03970156': 50, 'n04259630': 50, 'n07579787': 50, 'n02125311': 50, 'n04118538': 50, 'n03937543': 50, 'n02883205': 50, 'n03014705': 50, 'n04179913': 50, 'n03662601': 50, 'n03100240': 50, 'n02480495': 50, 'n04562935': 50, 'n01910747': 50, 'n02415577': 50, 'n02165456': 50, 'n02236044': 50, 'n07734744': 50, 'n04275548': 50, 'n02364673': 50, 'n02815834': 50, 'n03160309': 50, 'n02769748': 50, 'n02814533': 50, 'n01644900': 50}\n",
            "10000\n",
            "{'n02132136': 50, 'n03902125': 50, 'n03770439': 50, 'n03400231': 50, 'n02403003': 50, 'n02814860': 50, 'n03617480': 50, 'n04486054': 50, 'n04311004': 50, 'n04074963': 50, 'n03891332': 50, 'n02509815': 50, 'n04285008': 50, 'n01784675': 50, 'n02190166': 50, 'n01774750': 50, 'n02948072': 50, 'n04560804': 50, 'n03355925': 50, 'n03255030': 50, 'n07615774': 50, 'n03544143': 50, 'n03042490': 50, 'n02841315': 50, 'n04456115': 50, 'n02793495': 50, 'n02795169': 50, 'n02977058': 50, 'n07753592': 50, 'n09193705': 50, 'n03179701': 50, 'n04376876': 50, 'n01770393': 50, 'n02281406': 50, 'n02321529': 50, 'n02906734': 50, 'n02999410': 50, 'n01983481': 50, 'n07747607': 50, 'n02106662': 50, 'n02085620': 50, 'n03992509': 50, 'n02669723': 50, 'n04251144': 50, 'n02231487': 50, 'n04487081': 50, 'n02963159': 50, 'n02481823': 50, 'n07873807': 50, 'n02094433': 50, 'n02437312': 50, 'n02099601': 50, 'n02988304': 50, 'n03201208': 50, 'n02058221': 50, 'n07583066': 50, 'n04070727': 50, 'n02699494': 50, 'n02410509': 50, 'n03393912': 50, 'n04532106': 50, 'n07715103': 50, 'n03404251': 50, 'n03837869': 50, 'n03763968': 50, 'n03854065': 50, 'n04067472': 50, 'n03089624': 50, 'n02002724': 50, 'n09256479': 50, 'n03796401': 50, 'n04149813': 50, 'n02802426': 50, 'n02791270': 50, 'n02788148': 50, 'n02056570': 50, 'n02927161': 50, 'n02395406': 50, 'n04398044': 50, 'n04328186': 50, 'n03977966': 50, 'n01882714': 50, 'n02950826': 50, 'n02730930': 50, 'n01768244': 50, 'n03388043': 50, 'n04008634': 50, 'n03085013': 50, 'n03250847': 50, 'n07695742': 50, 'n02808440': 50, 'n02268443': 50, 'n03814639': 50, 'n02206856': 50, 'n07920052': 50, 'n04133789': 50, 'n04146614': 50, 'n02074367': 50, 'n02099712': 50, 'n04399382': 50, 'n04501370': 50, 'n02233338': 50, 'n03980874': 50, 'n04099969': 50, 'n07720875': 50, 'n07768694': 50, 'n01917289': 50, 'n04371430': 50, 'n02837789': 50, 'n04540053': 50, 'n07749582': 50, 'n02917067': 50, 'n03670208': 50, 'n04532670': 50, 'n07875152': 50, 'n01984695': 50, 'n07871810': 50, 'n03599486': 50, 'n09428293': 50, 'n02129165': 50, 'n01698640': 50, 'n02123045': 50, 'n02666196': 50, 'n03930313': 50, 'n01945685': 50, 'n02113799': 50, 'n01443537': 50, 'n02892201': 50, 'n01855672': 50, 'n04356056': 50, 'n03126707': 50, 'n03447447': 50, 'n01950731': 50, 'n03026506': 50, 'n03976657': 50, 'n03424325': 50, 'n01641577': 50, 'n04254777': 50, 'n04597913': 50, 'n02123394': 50, 'n12267677': 50, 'n02504458': 50, 'n02226429': 50, 'n02423022': 50, 'n07614500': 50, 'n02843684': 50, 'n03637318': 50, 'n04596742': 50, 'n02279972': 50, 'n02909870': 50, 'n04417672': 50, 'n04023962': 50, 'n04366367': 50, 'n03983396': 50, 'n03804744': 50, 'n01629819': 50, 'n02124075': 50, 'n03706229': 50, 'n09246464': 50, 'n03444034': 50, 'n01944390': 50, 'n06596364': 50, 'n03584254': 50, 'n03733131': 50, 'n02486410': 50, 'n01742172': 50, 'n01774384': 50, 'n03838899': 50, 'n04265275': 50, 'n04507155': 50, 'n02823428': 50, 'n09332890': 50, 'n03649909': 50, 'n07711569': 50, 'n04465501': 50, 'n03970156': 50, 'n04259630': 50, 'n07579787': 50, 'n02125311': 50, 'n04118538': 50, 'n03937543': 50, 'n02883205': 50, 'n03014705': 50, 'n04179913': 50, 'n03662601': 50, 'n03100240': 50, 'n02480495': 50, 'n04562935': 50, 'n01910747': 50, 'n02415577': 50, 'n02165456': 50, 'n02236044': 50, 'n07734744': 50, 'n04275548': 50, 'n02364673': 50, 'n02815834': 50, 'n03160309': 50, 'n02769748': 50, 'n02814533': 50, 'n01644900': 50}\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZSWpcLN9u-y",
        "colab_type": "code",
        "outputId": "6d17fe8a-d7d4-46ba-dfb6-c14158362e4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4124
        }
      },
      "source": [
        "## For checking the X_test and Y_test and their One Hot Encoding\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n",
        "print(pre_Y_test[:10])\n",
        "print(Y_test[:10])\n",
        "print(np.argmax(Y_test[453]))\n",
        "\n",
        "i = 453\n",
        "print(testing_labels[i])\n",
        "plt.imshow(testing_images[i])\n",
        "\n",
        "## Getting a map of classnames and their respective encoded value\n",
        "infer_encoded_val = list(set(testing_labels))\n",
        "infer_encoded_int_val = le.transform(infer_encoded_val)\n",
        "infer_encoded_int_list_val = list(infer_encoded_int_val)\n",
        "\n",
        "test_class_mapped = zip(infer_encoded_val,infer_encoded_int_list_val)\n",
        "test_class_mapped = set(train_class_mapped)\n",
        "test_class_mapped"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 64, 64, 3)\n",
            "(10000, 200)\n",
            "[ 64 111 130  41 125  25 122  11 197  37]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "24\n",
            "n02085620\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('n01443537', 0),\n",
              " ('n01629819', 1),\n",
              " ('n01641577', 2),\n",
              " ('n01644900', 3),\n",
              " ('n01698640', 4),\n",
              " ('n01742172', 5),\n",
              " ('n01768244', 6),\n",
              " ('n01770393', 7),\n",
              " ('n01774384', 8),\n",
              " ('n01774750', 9),\n",
              " ('n01784675', 10),\n",
              " ('n01855672', 11),\n",
              " ('n01882714', 12),\n",
              " ('n01910747', 13),\n",
              " ('n01917289', 14),\n",
              " ('n01944390', 15),\n",
              " ('n01945685', 16),\n",
              " ('n01950731', 17),\n",
              " ('n01983481', 18),\n",
              " ('n01984695', 19),\n",
              " ('n02002724', 20),\n",
              " ('n02056570', 21),\n",
              " ('n02058221', 22),\n",
              " ('n02074367', 23),\n",
              " ('n02085620', 24),\n",
              " ('n02094433', 25),\n",
              " ('n02099601', 26),\n",
              " ('n02099712', 27),\n",
              " ('n02106662', 28),\n",
              " ('n02113799', 29),\n",
              " ('n02123045', 30),\n",
              " ('n02123394', 31),\n",
              " ('n02124075', 32),\n",
              " ('n02125311', 33),\n",
              " ('n02129165', 34),\n",
              " ('n02132136', 35),\n",
              " ('n02165456', 36),\n",
              " ('n02190166', 37),\n",
              " ('n02206856', 38),\n",
              " ('n02226429', 39),\n",
              " ('n02231487', 40),\n",
              " ('n02233338', 41),\n",
              " ('n02236044', 42),\n",
              " ('n02268443', 43),\n",
              " ('n02279972', 44),\n",
              " ('n02281406', 45),\n",
              " ('n02321529', 46),\n",
              " ('n02364673', 47),\n",
              " ('n02395406', 48),\n",
              " ('n02403003', 49),\n",
              " ('n02410509', 50),\n",
              " ('n02415577', 51),\n",
              " ('n02423022', 52),\n",
              " ('n02437312', 53),\n",
              " ('n02480495', 54),\n",
              " ('n02481823', 55),\n",
              " ('n02486410', 56),\n",
              " ('n02504458', 57),\n",
              " ('n02509815', 58),\n",
              " ('n02666196', 59),\n",
              " ('n02669723', 60),\n",
              " ('n02699494', 61),\n",
              " ('n02730930', 62),\n",
              " ('n02769748', 63),\n",
              " ('n02788148', 64),\n",
              " ('n02791270', 65),\n",
              " ('n02793495', 66),\n",
              " ('n02795169', 67),\n",
              " ('n02802426', 68),\n",
              " ('n02808440', 69),\n",
              " ('n02814533', 70),\n",
              " ('n02814860', 71),\n",
              " ('n02815834', 72),\n",
              " ('n02823428', 73),\n",
              " ('n02837789', 74),\n",
              " ('n02841315', 75),\n",
              " ('n02843684', 76),\n",
              " ('n02883205', 77),\n",
              " ('n02892201', 78),\n",
              " ('n02906734', 79),\n",
              " ('n02909870', 80),\n",
              " ('n02917067', 81),\n",
              " ('n02927161', 82),\n",
              " ('n02948072', 83),\n",
              " ('n02950826', 84),\n",
              " ('n02963159', 85),\n",
              " ('n02977058', 86),\n",
              " ('n02988304', 87),\n",
              " ('n02999410', 88),\n",
              " ('n03014705', 89),\n",
              " ('n03026506', 90),\n",
              " ('n03042490', 91),\n",
              " ('n03085013', 92),\n",
              " ('n03089624', 93),\n",
              " ('n03100240', 94),\n",
              " ('n03126707', 95),\n",
              " ('n03160309', 96),\n",
              " ('n03179701', 97),\n",
              " ('n03201208', 98),\n",
              " ('n03250847', 99),\n",
              " ('n03255030', 100),\n",
              " ('n03355925', 101),\n",
              " ('n03388043', 102),\n",
              " ('n03393912', 103),\n",
              " ('n03400231', 104),\n",
              " ('n03404251', 105),\n",
              " ('n03424325', 106),\n",
              " ('n03444034', 107),\n",
              " ('n03447447', 108),\n",
              " ('n03544143', 109),\n",
              " ('n03584254', 110),\n",
              " ('n03599486', 111),\n",
              " ('n03617480', 112),\n",
              " ('n03637318', 113),\n",
              " ('n03649909', 114),\n",
              " ('n03662601', 115),\n",
              " ('n03670208', 116),\n",
              " ('n03706229', 117),\n",
              " ('n03733131', 118),\n",
              " ('n03763968', 119),\n",
              " ('n03770439', 120),\n",
              " ('n03796401', 121),\n",
              " ('n03804744', 122),\n",
              " ('n03814639', 123),\n",
              " ('n03837869', 124),\n",
              " ('n03838899', 125),\n",
              " ('n03854065', 126),\n",
              " ('n03891332', 127),\n",
              " ('n03902125', 128),\n",
              " ('n03930313', 129),\n",
              " ('n03937543', 130),\n",
              " ('n03970156', 131),\n",
              " ('n03976657', 132),\n",
              " ('n03977966', 133),\n",
              " ('n03980874', 134),\n",
              " ('n03983396', 135),\n",
              " ('n03992509', 136),\n",
              " ('n04008634', 137),\n",
              " ('n04023962', 138),\n",
              " ('n04067472', 139),\n",
              " ('n04070727', 140),\n",
              " ('n04074963', 141),\n",
              " ('n04099969', 142),\n",
              " ('n04118538', 143),\n",
              " ('n04133789', 144),\n",
              " ('n04146614', 145),\n",
              " ('n04149813', 146),\n",
              " ('n04179913', 147),\n",
              " ('n04251144', 148),\n",
              " ('n04254777', 149),\n",
              " ('n04259630', 150),\n",
              " ('n04265275', 151),\n",
              " ('n04275548', 152),\n",
              " ('n04285008', 153),\n",
              " ('n04311004', 154),\n",
              " ('n04328186', 155),\n",
              " ('n04356056', 156),\n",
              " ('n04366367', 157),\n",
              " ('n04371430', 158),\n",
              " ('n04376876', 159),\n",
              " ('n04398044', 160),\n",
              " ('n04399382', 161),\n",
              " ('n04417672', 162),\n",
              " ('n04456115', 163),\n",
              " ('n04465501', 164),\n",
              " ('n04486054', 165),\n",
              " ('n04487081', 166),\n",
              " ('n04501370', 167),\n",
              " ('n04507155', 168),\n",
              " ('n04532106', 169),\n",
              " ('n04532670', 170),\n",
              " ('n04540053', 171),\n",
              " ('n04560804', 172),\n",
              " ('n04562935', 173),\n",
              " ('n04596742', 174),\n",
              " ('n04597913', 175),\n",
              " ('n06596364', 176),\n",
              " ('n07579787', 177),\n",
              " ('n07583066', 178),\n",
              " ('n07614500', 179),\n",
              " ('n07615774', 180),\n",
              " ('n07695742', 181),\n",
              " ('n07711569', 182),\n",
              " ('n07715103', 183),\n",
              " ('n07720875', 184),\n",
              " ('n07734744', 185),\n",
              " ('n07747607', 186),\n",
              " ('n07749582', 187),\n",
              " ('n07753592', 188),\n",
              " ('n07768694', 189),\n",
              " ('n07871810', 190),\n",
              " ('n07873807', 191),\n",
              " ('n07875152', 192),\n",
              " ('n07920052', 193),\n",
              " ('n09193705', 194),\n",
              " ('n09246464', 195),\n",
              " ('n09256479', 196),\n",
              " ('n09332890', 197),\n",
              " ('n09428293', 198),\n",
              " ('n12267677', 199)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwrewqED8X4kqofJjOQkTAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfJCrRDZ-sdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train /= 128.\n",
        "X_test /= 128."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT3F5Pr4ZFzZ",
        "colab_type": "code",
        "outputId": "d966b5bd-98a2-4573-ec45-21bfdc5dd0f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_class_mapped == train_class_mapped"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-5mklf4Hnf0",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP93H2eiyvue",
        "colab_type": "text"
      },
      "source": [
        "## Libraries and model building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpNYW-FVoYCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers.merge import add\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Flatten, Input, merge, Activation,SeparableConv2D\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.advanced_activations import LeakyReLU,ReLU\n",
        "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Lambda\n",
        "from keras.layers.merge import concatenate\n",
        "\n",
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))\n",
        "\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers.merge import add\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzYbnsjdudBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def space_to_depth_x2(x):\n",
        "    return tf.space_to_depth(x, block_size=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSHNKMJfukwp",
        "colab_type": "code",
        "outputId": "12a8e62b-dec9-4c63-cb55-f1e5bd7dc603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "def blocks(inp, kernel_nos, n):\n",
        "\n",
        "  layer1 = Conv2D(kernel_nos, (3,3), strides=(1,1), padding='same', use_bias=False)(inp)\n",
        "  layer1 = BatchNormalization()(layer1)\n",
        "  layer1 = LeakyReLU(alpha=0.1)(layer1)\n",
        "  \n",
        "  kernel_nos *= 2\n",
        " \n",
        "  layer2 = Conv2D(kernel_nos, (3,3), strides=(1,1), padding='same', use_bias=False)(layer1)\n",
        "  layer2 = BatchNormalization()(layer2)\n",
        "  layer2 = LeakyReLU(alpha=0.1)(layer2)\n",
        "    \n",
        "  kernel_nos *= 2\n",
        "\n",
        "  layer3 = Conv2D(kernel_nos, (3,3), strides=(1,1), padding='same', use_bias=False)(layer2)\n",
        "  layer3 = BatchNormalization()(layer3)\n",
        "  layer3 = LeakyReLU(alpha=0.1)(layer3)\n",
        "    \n",
        "  if n==1:\n",
        "    kernel_nos = 96\n",
        "  elif n==2:\n",
        "    kernel_nos = 128\n",
        "  else:\n",
        "    kernel_nos *= 2\n",
        "\n",
        "  layer4 = Conv2D(kernel_nos, (3,3), strides=(1,1), padding='same', use_bias=False)(layer3)\n",
        "  layer4 = BatchNormalization()(layer4)\n",
        "  layer4 = LeakyReLU(alpha=0.1)(layer4)\n",
        "  \n",
        "  if n==1:\n",
        "    kernel_nos = 148\n",
        "  elif n==2:\n",
        "    kernel_nos = 124\n",
        "  elif n==3:\n",
        "    kernel_nos = 640\n",
        "  else:\n",
        "    kernel_nos *= 2\n",
        "\n",
        "  layer5 = Conv2D(kernel_nos, (3,3), strides=(1,1), padding='same', use_bias=False)(layer4)\n",
        "  layer5 = BatchNormalization()(layer5)\n",
        "  layer5 = LeakyReLU(alpha=0.1)(layer5)\n",
        "  \n",
        "  return layer5\n",
        "\n",
        "\n",
        "input = Input(shape=(None, None, 3,))\n",
        "\n",
        "block1 = blocks(input, 16, 1)\n",
        "#add 1X1 --84\n",
        "skip_connection1 = block1\n",
        "skip_connection1 = Conv2D(32, (1,1), strides=(1,1), padding='same', use_bias=False)(skip_connection1)\n",
        "skip_connection1 = Lambda(space_to_depth_x2)(skip_connection1)\n",
        "\n",
        "block2 = blocks(block1, 24, 2)\n",
        "#add 1X1 --84\n",
        "block2 = MaxPooling2D(pool_size=(2, 2))(block2)\n",
        "\n",
        "concat1_2 = concatenate([skip_connection1, block2])\n",
        "#add 1X1 before passing concat to next block\n",
        "block3 = blocks(concat1_2, 48, 3)\n",
        "#add 1X1\n",
        "block3 = MaxPooling2D(pool_size=(2, 2))(block3)\n",
        "\n",
        "skip_connection2 = Conv2D(64, (1,1), strides=(1,1), padding='same', use_bias=False)(concat1_2)\n",
        "skip_connection2 = Lambda(space_to_depth_x2)(skip_connection2)\n",
        "\n",
        "concat2_3 = concatenate([skip_connection2, block3])\n",
        "\n",
        "concat = Conv2D(1024, (1,1), strides=(1,1), padding='same', use_bias=False)(concat2_3)\n",
        "concat = Conv2D(nb_classes, (1,1), strides=(1,1), padding='same', use_bias=False)(concat)\n",
        "\n",
        "concat = GlobalAveragePooling2D()(concat)\n",
        "output = Activation('softmax')(concat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qm9dXbIMdI0",
        "colab_type": "code",
        "outputId": "52ff060a-a94f-43e7-fb1d-c071b5daba39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2290
        }
      },
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, None, None, 1 432         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, None, None, 1 64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, None, None, 3 4608        leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, None, None, 3 128         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, None, None, 3 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, None, None, 6 18432       leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, None, None, 6 256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, None, None, 9 55296       leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, None, None, 9 384         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, None, None, 9 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, None, None, 1 127872      leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, None, None, 1 592         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, None, None, 2 31968       leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, None, None, 2 96          conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, None, None, 2 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, None, None, 4 10368       leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, None, None, 4 192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, None, None, 4 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, None, None, 9 41472       leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, None, None, 9 384         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, None, None, 9 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, None, None, 1 110592      leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, None, None, 1 512         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, None, None, 1 142848      leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, None, None, 1 496         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, None, None, 3 4736        leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, None, None, 1 0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 1 0           leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, None, None, 2 0           lambda_1[0][0]                   \n",
            "                                                                 max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, None, None, 4 108864      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, None, None, 4 192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, None, None, 4 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, None, None, 9 41472       leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, None, None, 9 384         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)      (None, None, None, 9 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, None, None, 1 165888      leaky_re_lu_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, None, None, 1 768         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, None, None, 3 663552      leaky_re_lu_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, None, None, 3 1536        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)      (None, None, None, 3 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, None, None, 6 2211840     leaky_re_lu_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, None, None, 6 2560        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, None, None, 6 16128       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)      (None, None, None, 6 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, None, None, 2 0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 6 0           leaky_re_lu_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, None, None, 8 0           lambda_2[0][0]                   \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, None, None, 1 917504      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, None, None, 2 204800      conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 200)          0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 200)          0           global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 4,887,216\n",
            "Trainable params: 4,882,944\n",
            "Non-trainable params: 4,272\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZoeNFe61Je5",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IfaR3MnrBaY",
        "colab_type": "text"
      },
      "source": [
        "### Training on 32X32 image size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JEcCmsuNfw7",
        "colab_type": "code",
        "outputId": "88e1875e-5275-4178-dfb2-74812fcb7a5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n",
        "\n",
        "plt.imshow(X_train[83456])\n",
        "print(np.argmax(Y_train[83456]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(100000, 32, 32, 3)\n",
            "(100000, 200)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 200)\n",
            "174\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a53BW2CNPIgm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Setting hyperparameters and callbacks\n",
        "\n",
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping, ModelCheckpoint\n",
        "import numpy as np\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
        "csv_logger = CSVLogger('tinyImageNet.csv')\n",
        "\n",
        "filepath=\"/content/drive/My Drive/ass4/_epochs:{epoch:03d}-acc:{acc:.3f}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=3)\n",
        "callbacks_list = [checkpoint, lr_reducer, csv_logger ]\n",
        "\n",
        "epochs = 12\n",
        "learning_rate = 0.01\n",
        "decay_rate = learning_rate / epochs\n",
        "momentum = 0.9\n",
        "\n",
        "## Compiling\n",
        "sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu3_EzTTPXYX",
        "colab_type": "code",
        "outputId": "775e493a-8729-4c20-edfe-d886c837e508",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "model.fit(X_train, Y_train,\n",
        "          batch_size=1024,\n",
        "          nb_epoch=epochs,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          shuffle=True,\n",
        "          callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 100000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "100000/100000 [==============================] - 376s 4ms/step - loss: 4.5126 - acc: 0.0809 - val_loss: 4.8652 - val_acc: 0.0743\n",
            "Epoch 2/12\n",
            "100000/100000 [==============================] - 357s 4ms/step - loss: 3.7666 - acc: 0.1740 - val_loss: 3.7499 - val_acc: 0.1753\n",
            "Epoch 3/12\n",
            "100000/100000 [==============================] - 357s 4ms/step - loss: 3.4084 - acc: 0.2319 - val_loss: 3.6868 - val_acc: 0.2021\n",
            "\n",
            "Epoch 00003: val_acc improved from -inf to 0.20210, saving model to /content/drive/My Drive/ass4/_epochs:003-acc:0.232-val_acc:0.202.hdf5\n",
            "Epoch 4/12\n",
            "100000/100000 [==============================] - 357s 4ms/step - loss: 3.1659 - acc: 0.2748 - val_loss: 3.3317 - val_acc: 0.2443\n",
            "Epoch 5/12\n",
            "100000/100000 [==============================] - 357s 4ms/step - loss: 2.9830 - acc: 0.3089 - val_loss: 3.2436 - val_acc: 0.2613\n",
            "Epoch 6/12\n",
            "100000/100000 [==============================] - 357s 4ms/step - loss: 2.8426 - acc: 0.3341 - val_loss: 3.0343 - val_acc: 0.3057\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.20210 to 0.30570, saving model to /content/drive/My Drive/ass4/_epochs:006-acc:0.334-val_acc:0.306.hdf5\n",
            "Epoch 7/12\n",
            "100000/100000 [==============================] - 357s 4ms/step - loss: 2.7246 - acc: 0.3592 - val_loss: 2.9903 - val_acc: 0.3183\n",
            "Epoch 8/12\n",
            "100000/100000 [==============================] - 358s 4ms/step - loss: 2.6246 - acc: 0.3765 - val_loss: 2.9572 - val_acc: 0.3218\n",
            "Epoch 9/12\n",
            "100000/100000 [==============================] - 358s 4ms/step - loss: 2.5321 - acc: 0.3965 - val_loss: 2.8731 - val_acc: 0.3387\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.30570 to 0.33870, saving model to /content/drive/My Drive/ass4/_epochs:009-acc:0.396-val_acc:0.339.hdf5\n",
            "Epoch 10/12\n",
            "100000/100000 [==============================] - 357s 4ms/step - loss: 2.4510 - acc: 0.4126 - val_loss: 2.8183 - val_acc: 0.3411\n",
            "Epoch 11/12\n",
            "100000/100000 [==============================] - 361s 4ms/step - loss: 2.3773 - acc: 0.4274 - val_loss: 2.8222 - val_acc: 0.3435\n",
            "Epoch 12/12\n",
            "100000/100000 [==============================] - 361s 4ms/step - loss: 2.3129 - acc: 0.4410 - val_loss: 2.8119 - val_acc: 0.3449\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.33870 to 0.34490, saving model to /content/drive/My Drive/ass4/_epochs:012-acc:0.441-val_acc:0.345.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f398856f828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-5helxJk28E",
        "colab_type": "text"
      },
      "source": [
        "### Training for 16x16\n",
        "- I am changing image size by running code chunk from above\n",
        "- Below code prints the shape of X_train, Y_train, X_test, Y_test after loading of images are done in 16X16 size\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBOXhnRCkmMF",
        "colab_type": "code",
        "outputId": "bbebb206-5065-45d9-c7fb-41c0e92f37ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000, 16, 16, 3)\n",
            "(100000, 200)\n",
            "(10000, 16, 16, 3)\n",
            "(10000, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqg2WSeanSak",
        "colab_type": "code",
        "outputId": "c8b3cce2-23c8-46a6-b0c5-9bed377eb68d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "filepath=\"/content/drive/My Drive/ass4/_32_16_epochs:{epoch:03d}-acc:{acc:.3f}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=3)\n",
        "callbacks_list = [checkpoint, lr_reducer, csv_logger ]\n",
        "\n",
        "epochs = 9\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=1024,\n",
        "          nb_epoch=epochs,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          shuffle=True,\n",
        "          callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 100000 samples, validate on 10000 samples\n",
            "Epoch 1/9\n",
            "100000/100000 [==============================] - 104s 1ms/step - loss: 3.1571 - acc: 0.2888 - val_loss: 3.4384 - val_acc: 0.2438\n",
            "Epoch 2/9\n",
            "100000/100000 [==============================] - 92s 921us/step - loss: 2.9716 - acc: 0.3141 - val_loss: 3.2440 - val_acc: 0.2748\n",
            "Epoch 3/9\n",
            "100000/100000 [==============================] - 92s 920us/step - loss: 2.8838 - acc: 0.3306 - val_loss: 3.1833 - val_acc: 0.2821\n",
            "\n",
            "Epoch 00003: val_acc improved from -inf to 0.28210, saving model to /content/drive/My Drive/ass4/_32_16_epochs:003-acc:0.331-val_acc:0.282.hdf5\n",
            "Epoch 4/9\n",
            "100000/100000 [==============================] - 92s 922us/step - loss: 2.8187 - acc: 0.3424 - val_loss: 3.1610 - val_acc: 0.2908\n",
            "Epoch 5/9\n",
            "100000/100000 [==============================] - 92s 922us/step - loss: 2.7616 - acc: 0.3544 - val_loss: 3.1560 - val_acc: 0.2914\n",
            "Epoch 6/9\n",
            "100000/100000 [==============================] - 92s 919us/step - loss: 2.7091 - acc: 0.3635 - val_loss: 3.1301 - val_acc: 0.2949\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.28210 to 0.29490, saving model to /content/drive/My Drive/ass4/_32_16_epochs:006-acc:0.364-val_acc:0.295.hdf5\n",
            "Epoch 7/9\n",
            "100000/100000 [==============================] - 92s 922us/step - loss: 2.6640 - acc: 0.3716 - val_loss: 3.1394 - val_acc: 0.2920\n",
            "Epoch 8/9\n",
            "100000/100000 [==============================] - 92s 922us/step - loss: 2.6195 - acc: 0.3816 - val_loss: 3.1424 - val_acc: 0.2928\n",
            "Epoch 9/9\n",
            "100000/100000 [==============================] - 92s 921us/step - loss: 2.5764 - acc: 0.3900 - val_loss: 3.1171 - val_acc: 0.2969\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.29490 to 0.29690, saving model to /content/drive/My Drive/ass4/_32_16_epochs:009-acc:0.390-val_acc:0.297.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f396e2da7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF2CJJKYvcZ_",
        "colab_type": "text"
      },
      "source": [
        "### Training for 64X64\n",
        "- I am changing image size by running code chunk from above\n",
        "- Below code prints the shape of X_train, Y_train, X_test, Y_test after loading of images are done in 64X64 size\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZNo-i9KxpyD",
        "colab_type": "code",
        "outputId": "fd00d403-5812-475b-941f-e1ecd925b28d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000, 64, 64, 3)\n",
            "(100000, 200)\n",
            "(10000, 64, 64, 3)\n",
            "(10000, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_-9eC6Axojd",
        "colab_type": "code",
        "outputId": "b1ae7b6c-1aab-4c56-c0ce-727eb23b591a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "filepath=\"/content/drive/My Drive/ass4/_32_16_64_epochs:{epoch:03d}-acc:{acc:.3f}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "callbacks_list = [checkpoint, lr_reducer, csv_logger ]\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=128,\n",
        "          nb_epoch=epochs,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          shuffle=True,\n",
        "          callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 100000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "100000/100000 [==============================] - 1813s 18ms/step - loss: 2.8058 - acc: 0.3481 - val_loss: 2.8848 - val_acc: 0.3303\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.33030, saving model to /content/drive/My Drive/ass4/_32_16_64_epochs:001-acc:0.348-val_acc:0.330.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f396dfdccc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQtF4jlX5O8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Loading Model from the last 16X16 checkpoint  \n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "model = load_model('/content/drive/My Drive/ass4/_32_16_epochs:009-acc:0.390-val_acc:0.297.hdf5',custom_objects={'tf': tf})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UW1NEba8IBD",
        "colab_type": "code",
        "outputId": "5e1d1c6b-ffb7-4d98-8769-e7de91c29289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger, ModelCheckpoint\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
        "csv_logger = CSVLogger('tinyImageNet.csv')\n",
        "\n",
        "\n",
        "filepath=\"/content/drive/My Drive/ass4/_32_16_64_epochs:{epoch:03d}-acc:{acc:.3f}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint, lr_reducer, csv_logger ]\n",
        "\n",
        "epochs = 9\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=128,\n",
        "          nb_epoch=epochs,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          shuffle=True,\n",
        "          callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 100000 samples, validate on 10000 samples\n",
            "Epoch 1/9\n",
            "100000/100000 [==============================] - 1934s 19ms/step - loss: 2.8071 - acc: 0.3475 - val_loss: 2.9046 - val_acc: 0.3271\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.32710, saving model to /content/drive/My Drive/ass4/_32_16_64_epochs:001-acc:0.348-val_acc:0.327.hdf5\n",
            "Epoch 2/9\n",
            "100000/100000 [==============================] - 1916s 19ms/step - loss: 2.5514 - acc: 0.3966 - val_loss: 3.0069 - val_acc: 0.3130\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.32710\n",
            "Epoch 3/9\n",
            "100000/100000 [==============================] - 1914s 19ms/step - loss: 2.4395 - acc: 0.4191 - val_loss: 2.8964 - val_acc: 0.3279\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.32710 to 0.32790, saving model to /content/drive/My Drive/ass4/_32_16_64_epochs:003-acc:0.419-val_acc:0.328.hdf5\n",
            "Epoch 4/9\n",
            "100000/100000 [==============================] - 1916s 19ms/step - loss: 2.3522 - acc: 0.4360 - val_loss: 2.8784 - val_acc: 0.3360\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.32790 to 0.33600, saving model to /content/drive/My Drive/ass4/_32_16_64_epochs:004-acc:0.436-val_acc:0.336.hdf5\n",
            "Epoch 5/9\n",
            "100000/100000 [==============================] - 1920s 19ms/step - loss: 2.2833 - acc: 0.4510 - val_loss: 2.5720 - val_acc: 0.3899\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.33600 to 0.38990, saving model to /content/drive/My Drive/ass4/_32_16_64_epochs:005-acc:0.451-val_acc:0.390.hdf5\n",
            "Epoch 6/9\n",
            "100000/100000 [==============================] - 1917s 19ms/step - loss: 2.2269 - acc: 0.4615 - val_loss: 2.5063 - val_acc: 0.4042\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.38990 to 0.40420, saving model to /content/drive/My Drive/ass4/_32_16_64_epochs:006-acc:0.462-val_acc:0.404.hdf5\n",
            "Epoch 7/9\n",
            "100000/100000 [==============================] - 1911s 19ms/step - loss: 2.1685 - acc: 0.4738 - val_loss: 2.5855 - val_acc: 0.3941\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.40420\n",
            "Epoch 8/9\n",
            "100000/100000 [==============================] - 1917s 19ms/step - loss: 2.1247 - acc: 0.4817 - val_loss: 2.8423 - val_acc: 0.3509\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.40420\n",
            "Epoch 9/9\n",
            "100000/100000 [==============================] - 1917s 19ms/step - loss: 2.0780 - acc: 0.4934 - val_loss: 2.4323 - val_acc: 0.4214\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.40420 to 0.42140, saving model to /content/drive/My Drive/ass4/_32_16_64_epochs:009-acc:0.493-val_acc:0.421.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9c147a9550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sqqT0OdUHY_",
        "colab_type": "text"
      },
      "source": [
        "### Training on 32X32 again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkmCbZ0nUNDw",
        "colab_type": "code",
        "outputId": "50563358-e565-44e0-90cb-c0412a8d2dc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n",
        "\n",
        "plt.imshow(X_train[83456])\n",
        "print(np.argmax(Y_train[83456]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(100000, 32, 32, 3)\n",
            "(100000, 200)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 200)\n",
            "161\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "940aA1zgUhvH",
        "colab_type": "code",
        "outputId": "27e4fd99-53e9-43c0-9f86-b3b83712ede3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "model2 = load_model('/content/drive/My Drive/ass4/_32_16_64_epochs:009-acc:0.493-val_acc:0.421.hdf5',custom_objects={'tf': tf})\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEnjNx3zUlgz",
        "colab_type": "code",
        "outputId": "4f8448c1-80bc-46a4-84fd-f3d41e69bc06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        }
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger, ModelCheckpoint\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
        "csv_logger = CSVLogger('tinyImageNet.csv')\n",
        "\n",
        "\n",
        "filepath=\"/content/drive/My Drive/ass4/_32_16_64_32_epochs:{epoch:03d}-acc:{acc:.3f}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=3)\n",
        "callbacks_list = [checkpoint, lr_reducer, csv_logger ]\n",
        "\n",
        "epochs = 12\n",
        "\n",
        "model2.fit(X_train, Y_train,\n",
        "          batch_size=256,\n",
        "          nb_epoch=epochs,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          shuffle=True,\n",
        "          callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 100000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "100000/100000 [==============================] - 406s 4ms/step - loss: 2.3056 - acc: 0.4467 - val_loss: 2.6119 - val_acc: 0.3969\n",
            "Epoch 2/12\n",
            "100000/100000 [==============================] - 383s 4ms/step - loss: 2.0941 - acc: 0.4850 - val_loss: 2.5308 - val_acc: 0.4097\n",
            "Epoch 3/12\n",
            "100000/100000 [==============================] - 384s 4ms/step - loss: 2.0177 - acc: 0.5016 - val_loss: 2.4976 - val_acc: 0.4166\n",
            "\n",
            "Epoch 00003: val_acc improved from -inf to 0.41660, saving model to /content/drive/My Drive/ass4/_32_16_64_32_epochs:003-acc:0.502-val_acc:0.417.hdf5\n",
            "Epoch 4/12\n",
            "100000/100000 [==============================] - 384s 4ms/step - loss: 1.9644 - acc: 0.5119 - val_loss: 2.4869 - val_acc: 0.4149\n",
            "Epoch 5/12\n",
            "100000/100000 [==============================] - 383s 4ms/step - loss: 1.9219 - acc: 0.5220 - val_loss: 2.5112 - val_acc: 0.4194\n",
            "Epoch 6/12\n",
            "100000/100000 [==============================] - 384s 4ms/step - loss: 1.8816 - acc: 0.5311 - val_loss: 2.4403 - val_acc: 0.4208\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.41660 to 0.42080, saving model to /content/drive/My Drive/ass4/_32_16_64_32_epochs:006-acc:0.531-val_acc:0.421.hdf5\n",
            "Epoch 7/12\n",
            "100000/100000 [==============================] - 383s 4ms/step - loss: 1.8478 - acc: 0.5386 - val_loss: 2.4986 - val_acc: 0.4260\n",
            "Epoch 8/12\n",
            "100000/100000 [==============================] - 383s 4ms/step - loss: 1.8130 - acc: 0.5471 - val_loss: 2.4638 - val_acc: 0.4236\n",
            "Epoch 9/12\n",
            "100000/100000 [==============================] - 381s 4ms/step - loss: 1.7830 - acc: 0.5527 - val_loss: 2.4521 - val_acc: 0.4232\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.42080 to 0.42320, saving model to /content/drive/My Drive/ass4/_32_16_64_32_epochs:009-acc:0.553-val_acc:0.423.hdf5\n",
            "Epoch 10/12\n",
            "100000/100000 [==============================] - 382s 4ms/step - loss: 1.7505 - acc: 0.5619 - val_loss: 2.4510 - val_acc: 0.4258\n",
            "Epoch 11/12\n",
            "100000/100000 [==============================] - 382s 4ms/step - loss: 1.7206 - acc: 0.5677 - val_loss: 2.4684 - val_acc: 0.4288\n",
            "Epoch 12/12\n",
            "100000/100000 [==============================] - 381s 4ms/step - loss: 1.6382 - acc: 0.5901 - val_loss: 2.3952 - val_acc: 0.4383\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.42320 to 0.43830, saving model to /content/drive/My Drive/ass4/_32_16_64_32_epochs:012-acc:0.590-val_acc:0.438.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdc6b37b080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXAfETrJ1RQV",
        "colab_type": "text"
      },
      "source": [
        "### Training on 16X16 again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjnengcT1XPh",
        "colab_type": "code",
        "outputId": "b8f9e44f-a242-4ea9-ebce-8b28eceb27ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000, 16, 16, 3)\n",
            "(100000, 200)\n",
            "(10000, 16, 16, 3)\n",
            "(10000, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djh6TgHL1bmY",
        "colab_type": "code",
        "outputId": "392dc4c7-0953-485f-89c8-69267b0aa5e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "filepath=\"/content/drive/My Drive/ass4/_32_16_64_32_16_epochs:{epoch:03d}-acc:{acc:.3f}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=3)\n",
        "\n",
        "callbacks_list = [checkpoint, lr_reducer, csv_logger ]\n",
        "\n",
        "epochs = 6\n",
        "\n",
        "model2.fit(X_train, Y_train,\n",
        "          batch_size=1024,\n",
        "          nb_epoch=epochs,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          shuffle=True,\n",
        "          callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 100000 samples, validate on 10000 samples\n",
            "Epoch 1/6\n",
            "100000/100000 [==============================] - 123s 1ms/step - loss: 3.5346 - acc: 0.2901 - val_loss: 3.7975 - val_acc: 0.2308\n",
            "Epoch 2/6\n",
            "100000/100000 [==============================] - 98s 977us/step - loss: 3.1277 - acc: 0.3193 - val_loss: 3.5308 - val_acc: 0.2667\n",
            "Epoch 3/6\n",
            "100000/100000 [==============================] - 97s 974us/step - loss: 2.9718 - acc: 0.3324 - val_loss: 3.4486 - val_acc: 0.2775\n",
            "\n",
            "Epoch 00003: val_acc improved from -inf to 0.27750, saving model to /content/drive/My Drive/ass4/_32_16_64_32_16_epochs:003-acc:0.332-val_acc:0.278.hdf5\n",
            "Epoch 4/6\n",
            "100000/100000 [==============================] - 97s 973us/step - loss: 2.8763 - acc: 0.3416 - val_loss: 3.3753 - val_acc: 0.2844\n",
            "Epoch 5/6\n",
            "100000/100000 [==============================] - 97s 974us/step - loss: 2.8119 - acc: 0.3502 - val_loss: 3.3210 - val_acc: 0.2900\n",
            "Epoch 6/6\n",
            "100000/100000 [==============================] - 98s 977us/step - loss: 2.7637 - acc: 0.3574 - val_loss: 3.2868 - val_acc: 0.2911\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.27750 to 0.29110, saving model to /content/drive/My Drive/ass4/_32_16_64_32_16_epochs:006-acc:0.357-val_acc:0.291.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdc4e8c1f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RwCji7aK1nH",
        "colab_type": "text"
      },
      "source": [
        "### Training for 64X64 again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr-UQVsCOCIa",
        "colab_type": "code",
        "outputId": "6f44cb54-3c50-4366-c89f-cdcaa6cdc843",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000, 64, 64, 3)\n",
            "(100000, 200)\n",
            "(10000, 64, 64, 3)\n",
            "(10000, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3rtu6UqnoXQ",
        "colab_type": "code",
        "outputId": "8e1f7a34-8993-4111-c95b-1035b735ff92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        }
      },
      "source": [
        "## loading model from previous checkpoint\n",
        "\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "model2 = load_model('/content/drive/My Drive/ass4/_32_16_64_32_16_epochs:006-acc:0.357-val_acc:0.291.hdf5',custom_objects={'tf': tf})\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPx43NkdoIoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger, ModelCheckpoint\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
        "csv_logger = CSVLogger('tinyImageNet.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU2vDJpHOOCn",
        "colab_type": "code",
        "outputId": "78e8c0d0-a121-4b86-ac4b-bbc28b516b89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "filepath=\"/content/drive/My Drive/ass4/_32_16_64_32_16_64_epochs:{epoch:03d}-acc:{acc:.3f}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=3)\n",
        "\n",
        "callbacks_list = [checkpoint, lr_reducer, csv_logger ]\n",
        "\n",
        "epochs = 9\n",
        "\n",
        "model2.fit(X_train, Y_train,\n",
        "          batch_size=128,\n",
        "          nb_epoch=epochs,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          shuffle=True,\n",
        "          callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 100000 samples, validate on 10000 samples\n",
            "Epoch 1/9\n",
            "100000/100000 [==============================] - 2079s 21ms/step - loss: 2.3069 - acc: 0.4554 - val_loss: 2.3819 - val_acc: 0.4344\n",
            "Epoch 2/9\n",
            "100000/100000 [==============================] - 2054s 21ms/step - loss: 2.0528 - acc: 0.5058 - val_loss: 2.3379 - val_acc: 0.4416\n",
            "Epoch 3/9\n",
            "100000/100000 [==============================] - 2051s 21ms/step - loss: 1.9822 - acc: 0.5205 - val_loss: 2.2719 - val_acc: 0.4571\n",
            "\n",
            "Epoch 00003: val_acc improved from -inf to 0.45710, saving model to /content/drive/My Drive/ass4/_32_16_64_32_16_64_epochs:003-acc:0.521-val_acc:0.457.hdf5\n",
            "Epoch 4/9\n",
            " 15488/100000 [===>..........................] - ETA: 28:04 - loss: 1.9338 - acc: 0.5326"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ-rvJ4cYewl",
        "colab_type": "code",
        "outputId": "644bd43c-0cab-4f3b-a61e-c55eb7e39db1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "## loading model from previous checkpoint\n",
        "\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "model2 = load_model('/content/drive/My Drive/ass4/_32_16_64_32_16_64_epochs:003-acc:0.521-val_acc:0.457.hdf5',custom_objects={'tf': tf})\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWopkRQbnGdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger, ModelCheckpoint\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
        "csv_logger = CSVLogger('tinyImageNet.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvzoYbPgYxWy",
        "colab_type": "code",
        "outputId": "b4d97b2c-0043-43b3-9fab-94cf3c629ea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "filepath=\"/content/drive/My Drive/ass4/_32_16_64_32_16_64_epochs:{epoch:03d}-acc:{acc:.3f}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=3)\n",
        "\n",
        "callbacks_list = [checkpoint, lr_reducer, csv_logger ]\n",
        "\n",
        "epochs = 6\n",
        "\n",
        "model2.fit(X_train, Y_train,\n",
        "          batch_size=128,\n",
        "          nb_epoch=epochs,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          shuffle=True,\n",
        "          callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 100000 samples, validate on 10000 samples\n",
            "Epoch 1/6\n",
            "100000/100000 [==============================] - 2059s 21ms/step - loss: 1.9417 - acc: 0.5287 - val_loss: 2.2625 - val_acc: 0.4559\n",
            "Epoch 2/6\n",
            "100000/100000 [==============================] - 2043s 20ms/step - loss: 1.9117 - acc: 0.5349 - val_loss: 2.2704 - val_acc: 0.4550\n",
            "Epoch 3/6\n",
            "100000/100000 [==============================] - 2042s 20ms/step - loss: 1.8895 - acc: 0.5398 - val_loss: 2.2604 - val_acc: 0.4543\n",
            "\n",
            "Epoch 00003: val_acc improved from -inf to 0.45430, saving model to /content/drive/My Drive/ass4/_32_16_64_32_16_64_epochs:003-acc:0.540-val_acc:0.454.hdf5\n",
            "Epoch 4/6\n",
            "100000/100000 [==============================] - 2042s 20ms/step - loss: 1.8705 - acc: 0.5447 - val_loss: 2.2360 - val_acc: 0.4639\n",
            "Epoch 5/6\n",
            "100000/100000 [==============================] - 2044s 20ms/step - loss: 1.8541 - acc: 0.5478 - val_loss: 2.2292 - val_acc: 0.4664\n",
            "Epoch 6/6\n",
            "100000/100000 [==============================] - 2046s 20ms/step - loss: 1.8390 - acc: 0.5504 - val_loss: 2.2161 - val_acc: 0.4699\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.45430 to 0.46990, saving model to /content/drive/My Drive/ass4/_32_16_64_32_16_64_epochs:006-acc:0.550-val_acc:0.470.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc219fc8e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNJwrBYCBIVo",
        "colab_type": "text"
      },
      "source": [
        "### 32X32 before applying augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfQgMZ1NBWsW",
        "colab_type": "code",
        "outputId": "7a3f5658-b8a6-44f3-94ca-53dec7ac150a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000, 32, 32, 3)\n",
            "(100000, 200)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeqOa4IfBYn0",
        "colab_type": "code",
        "outputId": "b2575077-4da9-4103-8aef-87a142d5a899",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger, ModelCheckpoint\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
        "csv_logger = CSVLogger('tinyImageNet.csv')\n",
        "\n",
        "\n",
        "filepath=\"/content/drive/My Drive/ass4/_32_16_64_32_16_64_32_epochs:{epoch:03d}-acc:{acc:.3f}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=3)\n",
        "callbacks_list = [checkpoint, lr_reducer, csv_logger ]\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "model2.fit(X_train, Y_train,\n",
        "          batch_size=256,\n",
        "          nb_epoch=epochs,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          shuffle=True,\n",
        "          callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 100000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "100000/100000 [==============================] - 393s 4ms/step - loss: 1.9586 - acc: 0.5130 - val_loss: 2.5140 - val_acc: 0.4248\n",
            "Epoch 2/3\n",
            "100000/100000 [==============================] - 377s 4ms/step - loss: 1.7610 - acc: 0.5559 - val_loss: 2.4420 - val_acc: 0.4306\n",
            "Epoch 3/3\n",
            "100000/100000 [==============================] - 376s 4ms/step - loss: 1.6946 - acc: 0.5716 - val_loss: 2.4186 - val_acc: 0.4343\n",
            "\n",
            "Epoch 00003: val_acc improved from -inf to 0.43430, saving model to /content/drive/My Drive/ass4/_32_16_64_32_16_64_32_epochs:003-acc:0.572-val_acc:0.434.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc2239685f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "potr3KPHKkbq",
        "colab_type": "text"
      },
      "source": [
        "### Keras in built augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVEcwWFkLjeN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping, ModelCheckpoint\n",
        "\n",
        "filepath=\"/content/drive/My Drive/ass4/_32_16_64_32_16_64_32_inbAug_epochs:{epoch:03d}-acc:{acc:.3f}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=3)\n",
        "callbacks_list = [checkpoint, lr_reducer, csv_logger ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClNQbvBeKrHO",
        "colab_type": "code",
        "outputId": "6680648d-59e6-4c82-ec79-75a1f7e8cc66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "print('Using real-time data augmentation.')\n",
        "# This will do preprocessing and realtime data augmentation:\n",
        "datagen = ImageDataGenerator(\n",
        "        zoom_range = 0.2,\n",
        "        rotation_range=30,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        shear_range=0.2,\n",
        "        fill_mode='nearest')\n",
        "    \n",
        "datagen.fit(X_train)\n",
        "\n",
        "\n",
        "# Fit the model on the batches generated by datagen.flow().\n",
        "model2.fit_generator(datagen.flow(X_train, Y_train, batch_size= 256),\n",
        "                        steps_per_epoch=X_train.shape[0] // 256,\n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        epochs=6, verbose=1, max_q_size=100,\n",
        "                        callbacks = callbacks_list)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=390, validation_data=(array([[[..., epochs=6, verbose=1, callbacks=[<keras.ca..., max_queue_size=100)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "390/390 [==============================] - 377s 967ms/step - loss: 2.8957 - acc: 0.3419 - val_loss: 3.1487 - val_acc: 0.3299\n",
            "Epoch 2/6\n",
            "390/390 [==============================] - 377s 967ms/step - loss: 2.7738 - acc: 0.3564 - val_loss: 3.0878 - val_acc: 0.3317\n",
            "Epoch 3/6\n",
            "390/390 [==============================] - 377s 966ms/step - loss: 2.7252 - acc: 0.3639 - val_loss: 3.2637 - val_acc: 0.3156\n",
            "\n",
            "Epoch 00003: val_acc improved from -inf to 0.31560, saving model to /content/drive/My Drive/ass4/_32_16_64_32_16_64_32_inbAug_epochs:003-acc:0.364-val_acc:0.316.hdf5\n",
            "Epoch 4/6\n",
            "390/390 [==============================] - 377s 966ms/step - loss: 2.7012 - acc: 0.3674 - val_loss: 3.1385 - val_acc: 0.3276\n",
            "Epoch 5/6\n",
            "390/390 [==============================] - 377s 966ms/step - loss: 2.6789 - acc: 0.3727 - val_loss: 3.1017 - val_acc: 0.3239\n",
            "Epoch 6/6\n",
            "390/390 [==============================] - 377s 967ms/step - loss: 2.6559 - acc: 0.3769 - val_loss: 3.0804 - val_acc: 0.3303\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.31560 to 0.33030, saving model to /content/drive/My Drive/ass4/_32_16_64_32_16_64_32_inbAug_epochs:006-acc:0.377-val_acc:0.330.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc21914a080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mPQdjx_XNXU",
        "colab_type": "code",
        "outputId": "1d44f7c0-23e2-4b93-bb0d-e7dc774399ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "model2.fit_generator(datagen.flow(X_train, Y_train, batch_size= 256),\n",
        "                        steps_per_epoch=X_train.shape[0] // 256,\n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        epochs=6, verbose=1, max_q_size=100,\n",
        "                        callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=390, validation_data=(array([[[..., epochs=6, verbose=1, callbacks=[<keras.ca..., max_queue_size=100)`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "390/390 [==============================] - 377s 967ms/step - loss: 2.6456 - acc: 0.3777 - val_loss: 3.1096 - val_acc: 0.3266\n",
            "Epoch 2/6\n",
            "390/390 [==============================] - 377s 966ms/step - loss: 2.6346 - acc: 0.3797 - val_loss: 3.0462 - val_acc: 0.3355\n",
            "Epoch 3/6\n",
            "390/390 [==============================] - 377s 966ms/step - loss: 2.6264 - acc: 0.3837 - val_loss: 3.0208 - val_acc: 0.3360\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.33030 to 0.33600, saving model to /content/drive/My Drive/ass4/_32_16_64_32_16_64_32_inbAug_epochs:003-acc:0.384-val_acc:0.336.hdf5\n",
            "Epoch 4/6\n",
            "390/390 [==============================] - 377s 966ms/step - loss: 2.6097 - acc: 0.3850 - val_loss: 3.0170 - val_acc: 0.3340\n",
            "Epoch 5/6\n",
            "390/390 [==============================] - 377s 966ms/step - loss: 2.6042 - acc: 0.3852 - val_loss: 3.0952 - val_acc: 0.3262\n",
            "Epoch 6/6\n",
            "390/390 [==============================] - 377s 966ms/step - loss: 2.5975 - acc: 0.3872 - val_loss: 3.1399 - val_acc: 0.3195\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.33600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc219055f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGEhh9ECrC78",
        "colab_type": "code",
        "outputId": "7db1514c-fb34-49fc-e451-846f07fdfe26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "## loading model from previous checkpoint\n",
        "\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "model2 = load_model('/content/drive/My Drive/ass4/_32_16_64_32_16_64_32_inbAug_epochs:003-acc:0.384-val_acc:0.336.hdf5',custom_objects={'tf': tf})\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy9LWST4rw5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping, ModelCheckpoint\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
        "csv_logger = CSVLogger('tinyImageNet.csv')\n",
        "\n",
        "filepath=\"/content/drive/My Drive/ass4/_32_16_64_32_16_64_32_inbAug2_epochs:{epoch:03d}-acc:{acc:.3f}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=3)\n",
        "callbacks_list = [checkpoint, lr_reducer, csv_logger ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GizeJyjQrtjv",
        "colab_type": "code",
        "outputId": "5b2d9c18-2b96-4b4d-e1c2-feb285679803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        }
      },
      "source": [
        "print('Using real-time data augmentation.')\n",
        "# This will do preprocessing and realtime data augmentation:\n",
        "datagen = ImageDataGenerator(\n",
        "        zoom_range = 0.2,\n",
        "        rotation_range=30,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        shear_range=0.2,\n",
        "        fill_mode='nearest')\n",
        "    \n",
        "datagen.fit(X_train)\n",
        "\n",
        "\n",
        "# Fit the model on the batches generated by datagen.flow().\n",
        "model2.fit_generator(datagen.flow(X_train, Y_train, batch_size= 256),\n",
        "                        steps_per_epoch=X_train.shape[0] // 256,\n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        epochs=15, verbose=1, max_q_size=100,\n",
        "                        callbacks = callbacks_list)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=390, validation_data=(array([[[..., epochs=15, verbose=1, callbacks=[<keras.ca..., max_queue_size=100)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "390/390 [==============================] - 379s 971ms/step - loss: 2.6095 - acc: 0.3868 - val_loss: 3.1687 - val_acc: 0.3139\n",
            "Epoch 2/15\n",
            "390/390 [==============================] - 371s 951ms/step - loss: 2.6005 - acc: 0.3851 - val_loss: 3.0625 - val_acc: 0.3324\n",
            "Epoch 3/15\n",
            "390/390 [==============================] - 364s 934ms/step - loss: 2.5969 - acc: 0.3873 - val_loss: 2.9813 - val_acc: 0.3388\n",
            "\n",
            "Epoch 00003: val_acc improved from -inf to 0.33880, saving model to /content/drive/My Drive/ass4/_32_16_64_32_16_64_32_inbAug2_epochs:003-acc:0.387-val_acc:0.339.hdf5\n",
            "Epoch 4/15\n",
            "390/390 [==============================] - 365s 935ms/step - loss: 2.5888 - acc: 0.3883 - val_loss: 2.9869 - val_acc: 0.3422\n",
            "Epoch 5/15\n",
            "390/390 [==============================] - 365s 935ms/step - loss: 2.5814 - acc: 0.3904 - val_loss: 3.0690 - val_acc: 0.3286\n",
            "Epoch 6/15\n",
            "390/390 [==============================] - 364s 935ms/step - loss: 2.5771 - acc: 0.3920 - val_loss: 2.9893 - val_acc: 0.3420\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.33880 to 0.34200, saving model to /content/drive/My Drive/ass4/_32_16_64_32_16_64_32_inbAug2_epochs:006-acc:0.392-val_acc:0.342.hdf5\n",
            "Epoch 7/15\n",
            "390/390 [==============================] - 364s 934ms/step - loss: 2.5672 - acc: 0.3923 - val_loss: 2.9974 - val_acc: 0.3397\n",
            "Epoch 8/15\n",
            "390/390 [==============================] - 365s 935ms/step - loss: 2.5622 - acc: 0.3940 - val_loss: 3.0900 - val_acc: 0.3288\n",
            "Epoch 9/15\n",
            "390/390 [==============================] - 365s 935ms/step - loss: 2.5520 - acc: 0.3952 - val_loss: 3.0523 - val_acc: 0.3305\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.34200\n",
            "Epoch 10/15\n",
            "390/390 [==============================] - 364s 934ms/step - loss: 2.5419 - acc: 0.3980 - val_loss: 3.0547 - val_acc: 0.3304\n",
            "Epoch 11/15\n",
            "390/390 [==============================] - 364s 934ms/step - loss: 2.5424 - acc: 0.3980 - val_loss: 3.0276 - val_acc: 0.3345\n",
            "Epoch 12/15\n",
            "390/390 [==============================] - 364s 934ms/step - loss: 2.5351 - acc: 0.3991 - val_loss: 3.0599 - val_acc: 0.3305\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.34200\n",
            "Epoch 13/15\n",
            "390/390 [==============================] - 364s 933ms/step - loss: 2.5363 - acc: 0.3981 - val_loss: 3.0228 - val_acc: 0.3356\n",
            "Epoch 14/15\n",
            "390/390 [==============================] - 364s 934ms/step - loss: 2.5329 - acc: 0.3989 - val_loss: 3.0362 - val_acc: 0.3318\n",
            "Epoch 15/15\n",
            "390/390 [==============================] - 365s 935ms/step - loss: 2.5370 - acc: 0.4008 - val_loss: 3.0241 - val_acc: 0.3350\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.34200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f07735d1eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwiMrE_6DzCA",
        "colab_type": "text"
      },
      "source": [
        "### Custom imgaug augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc8v5HjfDp5J",
        "colab_type": "code",
        "outputId": "e86ad8c9-094a-4e0e-a0d2-4f153e0fbdd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "# prerequisites for imgaug library\n",
        "!pip install six numpy scipy Pillow matplotlib scikit-image opencv-python imageio Shapely"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.0.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (0.13.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (3.4.5.20)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (1.6.4.post2)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow) (0.46)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.0.2)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (40.8.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.8->scikit-image) (4.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5C5s2HZsDG-",
        "colab_type": "code",
        "outputId": "8a4d19c4-1c68-4724-e53f-65adee03b421",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "# image augmentation library imgaug (https://github.com/aleju/imgaug)\n",
        "!pip install imgaug\n",
        "\n",
        "# NOTE: make sure to Restart Runtime after this installation completes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.6/dist-packages (0.2.8)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug) (0.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug) (4.1.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.1.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.6.4.post2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug) (2.4.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug) (3.4.5.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.11.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug) (3.0.3)\n",
            "Collecting numpy>=1.15.0 (from imgaug)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 17.3MB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug) (2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug) (1.0.2)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->imgaug) (0.46)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (2.3.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (2.5.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.8->scikit-image>=0.11.0->imgaug) (4.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug) (40.8.0)\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mdatascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "Successfully installed numpy-1.16.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZUYXZmYEGH5",
        "colab_type": "code",
        "outputId": "a634b980-45e7-4819-8d68-7d6c6dbbac5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        }
      },
      "source": [
        "# imgaug needs latest scikit module. so need to do this. else, will get some weird error related to numpy!\n",
        "!pip install --upgrade scikit-image\n",
        "\n",
        "# NOTE: make sure to Restart Runtime after this installation completes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-image\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/ab/674e168bf7d0bc597218b3bec858d02c23fbac9ec1fec9cad878c6cee95f/scikit_image-0.15.0-cp36-cp36m-manylinux1_x86_64.whl (26.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 26.3MB 1.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.0.2)\n",
            "Collecting pillow>=4.3.0 (from scikit-image)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/c2/f84b1e57416755e967236468dcfb0fad7fd911f707185efc4ba8834a1a94/Pillow-6.0.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 11.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.2)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (3.0.3)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from PyWavelets>=0.4.0->scikit-image) (1.16.2)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image) (4.4.0)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (40.8.0)\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pillow, scikit-image\n",
            "  Found existing installation: Pillow 4.1.1\n",
            "    Uninstalling Pillow-4.1.1:\n",
            "      Successfully uninstalled Pillow-4.1.1\n",
            "  Found existing installation: scikit-image 0.13.1\n",
            "    Uninstalling scikit-image-0.13.1:\n",
            "      Successfully uninstalled scikit-image-0.13.1\n",
            "Successfully installed pillow-6.0.0 scikit-image-0.15.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AXxpSsVJa1G",
        "colab_type": "code",
        "outputId": "9d01ccff-36a7-498a-bca3-70b185012dbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000, 32, 32, 3)\n",
            "(100000, 200)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0tVszdwEM5q",
        "colab_type": "code",
        "outputId": "a95b44cb-28f8-4fec-c465-4f60c009bbf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "## Loading model from previous checkpoint\n",
        "\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "model_aug = load_model('/content/drive/My Drive/ass4/_32_16_64_32_16_64_32_inbAug2_epochs:006-acc:0.392-val_acc:0.342.hdf5',custom_objects={'tf': tf})\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9pHmiYiHe8_",
        "colab_type": "code",
        "outputId": "db817b19-51b9-4b0a-fc7d-90f05c100814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "score = model_aug.evaluate(X_test, Y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 17s 2ms/step\n",
            "Test loss: 2.989250016784668\n",
            "Test accuracy: 0.342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z0XRjc1E49_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator,array_to_img\n",
        "import imageio\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "matplotlib.use('Agg')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEs3uoIAE5_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def customizedImgAug(input_img):\n",
        "    \"\"\"image augmentation using imgaug\n",
        "    Args:\n",
        "        input_img:\n",
        "            image to be augmented (numpy tensor with rank 3)\n",
        "    Return:\n",
        "        augmented image(numpy tensor with rank 3) \n",
        "    \"\"\"\n",
        "    seq = iaa.Sequential(\n",
        "        [    \n",
        "          iaa.Fliplr(0.5), # horizontal flips\n",
        "          # Small gaussian blur with random sigma between 0 and 0.2.\n",
        "          # But we only blur about 50% of all images.\n",
        "          # Strengthen or weaken the contrast in each image.\n",
        "          iaa.Sometimes(0.5,\n",
        "              iaa.GaussianBlur(sigma=(0, 0.3)),\n",
        "              iaa.Sharpen(alpha=0.4)\n",
        "          ),\n",
        "              \n",
        "          iaa.Sometimes(0.5,\n",
        "              iaa.Affine(shear=(-16, 16)),\n",
        "              iaa.ContrastNormalization((0.75, 1.5))\n",
        "          ),\n",
        "        # In 20% of all cases, we sample the multiplier once per channel,\n",
        "        # which can end up changing the color of the images.\n",
        "        iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
        "        # Augmenter that sets rectangular areas within images to zero\n",
        "        iaa.CoarseDropout((0.0, 0.12), size_percent=(0.10, 0.20)),\n",
        "        ],random_order = True) # apply augmenters in random order\n",
        "        \n",
        "    output_img = seq.augment_image(input_img)\n",
        "    return output_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNzMaqZ0FIhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        preprocessing_function = customizedImgAug)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAahhV2YFXGD",
        "colab_type": "code",
        "outputId": "a5abbfba-5c52-4e79-ccdb-64d73e01013a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "pics_num = 10\n",
        "figure = plt.figure(figsize=(14, 5))\n",
        "plt.subplots_adjust(left=0.1,bottom=0.1, right=0.9, top=0.9,hspace=0.5, wspace=0.3)\n",
        "for x_batch,y_batch in datagen.flow(X_train,Y_train,batch_size = pics_num):\n",
        "    for i in range(pics_num):\n",
        "        pics_raw = x_batch[i]\n",
        "        pics = array_to_img(pics_raw)\n",
        "        ax = plt.subplot(pics_num//5, 5, i+1)\n",
        "        ax.axis('off')\n",
        "        plt.imshow(pics)\n",
        "    plt.savefig(\"./processed_data.jpg\")\n",
        "    break   \n",
        "print(\"Everything seems OK...\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Everything seems OK...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzgAAAFBCAYAAAC7PgqiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQkLD/w/7cW1s2JsABAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1008x360 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oly6vEjAGItb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger, ModelCheckpoint\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
        "csv_logger = CSVLogger('tinyImageNet.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK1GMADdGOcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath=\"/content/drive/My Drive/ass4/__32_16_64_32_16_64_32_inb_IMGAUG_epochs:{epoch:03d}-acc:{acc:.3f}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=3)\n",
        "callbacks_list = [checkpoint, lr_reducer, csv_logger ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nllU8qMCGlVX",
        "colab_type": "code",
        "outputId": "742c88bc-c18e-4b22-e765-fadd4bc1647d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "datagen.fit(X_train)\n",
        "\n",
        "model_aug.fit_generator(datagen.flow(X_train, Y_train, batch_size= 32),\n",
        "                        steps_per_epoch=X_train.shape[0] // 32,\n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        epochs=15, verbose=1, max_q_size=100,\n",
        "                        callbacks = callbacks_list)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=3125, validation_data=(array([[[..., epochs=15, verbose=1, callbacks=[<keras.ca..., max_queue_size=100)`\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "3125/3125 [==============================] - 503s 161ms/step - loss: 2.7535 - acc: 0.3549 - val_loss: 2.5871 - val_acc: 0.3995\n",
            "Epoch 2/15\n",
            "3125/3125 [==============================] - 499s 160ms/step - loss: 2.6066 - acc: 0.3813 - val_loss: 2.5499 - val_acc: 0.4099\n",
            "Epoch 3/15\n",
            "3125/3125 [==============================] - 497s 159ms/step - loss: 2.5524 - acc: 0.3920 - val_loss: 2.4777 - val_acc: 0.4147\n",
            "\n",
            "Epoch 00003: val_acc improved from -inf to 0.41470, saving model to /content/drive/My Drive/ass4/__32_16_64_32_16_64_32_inb_IMGAUG_epochs:003-acc:0.392-val_acc:0.415.hdf5\n",
            "Epoch 4/15\n",
            "3125/3125 [==============================] - 495s 158ms/step - loss: 2.5079 - acc: 0.4023 - val_loss: 2.4555 - val_acc: 0.4231\n",
            "Epoch 5/15\n",
            "3125/3125 [==============================] - 496s 159ms/step - loss: 2.4811 - acc: 0.4063 - val_loss: 2.4228 - val_acc: 0.4245\n",
            "Epoch 6/15\n",
            "3125/3125 [==============================] - 496s 159ms/step - loss: 2.4530 - acc: 0.4132 - val_loss: 2.4394 - val_acc: 0.4264\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.41470 to 0.42640, saving model to /content/drive/My Drive/ass4/__32_16_64_32_16_64_32_inb_IMGAUG_epochs:006-acc:0.413-val_acc:0.426.hdf5\n",
            "Epoch 7/15\n",
            "3125/3125 [==============================] - 496s 159ms/step - loss: 2.4335 - acc: 0.4174 - val_loss: 2.4094 - val_acc: 0.4319\n",
            "Epoch 8/15\n",
            "3125/3125 [==============================] - 494s 158ms/step - loss: 2.4123 - acc: 0.4193 - val_loss: 2.4103 - val_acc: 0.4336\n",
            "Epoch 9/15\n",
            "3125/3125 [==============================] - 494s 158ms/step - loss: 2.3919 - acc: 0.4241 - val_loss: 2.4108 - val_acc: 0.4332\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.42640 to 0.43320, saving model to /content/drive/My Drive/ass4/__32_16_64_32_16_64_32_inb_IMGAUG_epochs:009-acc:0.424-val_acc:0.433.hdf5\n",
            "Epoch 10/15\n",
            "3125/3125 [==============================] - 494s 158ms/step - loss: 2.3830 - acc: 0.4241 - val_loss: 2.3894 - val_acc: 0.4380\n",
            "Epoch 11/15\n",
            "3125/3125 [==============================] - 495s 158ms/step - loss: 2.3666 - acc: 0.4295 - val_loss: 2.3894 - val_acc: 0.4391\n",
            "Epoch 12/15\n",
            "3125/3125 [==============================] - 495s 159ms/step - loss: 2.3501 - acc: 0.4335 - val_loss: 2.3606 - val_acc: 0.4423\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.43320 to 0.44230, saving model to /content/drive/My Drive/ass4/__32_16_64_32_16_64_32_inb_IMGAUG_epochs:012-acc:0.433-val_acc:0.442.hdf5\n",
            "Epoch 13/15\n",
            "3125/3125 [==============================] - 492s 157ms/step - loss: 2.3388 - acc: 0.4377 - val_loss: 2.3788 - val_acc: 0.4374\n",
            "Epoch 14/15\n",
            "3125/3125 [==============================] - 491s 157ms/step - loss: 2.3313 - acc: 0.4375 - val_loss: 2.3537 - val_acc: 0.4448\n",
            "Epoch 15/15\n",
            "3125/3125 [==============================] - 498s 159ms/step - loss: 2.3208 - acc: 0.4386 - val_loss: 2.3665 - val_acc: 0.4429\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.44230 to 0.44290, saving model to /content/drive/My Drive/ass4/__32_16_64_32_16_64_32_inb_IMGAUG_epochs:015-acc:0.439-val_acc:0.443.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5ce139fef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5n9DT65kfw7",
        "colab_type": "code",
        "outputId": "8594bbcc-e026-4b8f-f959-7eb5aa20a311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "model_aug.fit_generator(datagen.flow(X_train, Y_train, batch_size= 32),\n",
        "                        steps_per_epoch=X_train.shape[0] // 32,\n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        epochs=15, verbose=1, max_q_size=100,\n",
        "                        callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=3125, validation_data=(array([[[..., epochs=15, verbose=1, callbacks=[<keras.ca..., max_queue_size=100)`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "3125/3125 [==============================] - 494s 158ms/step - loss: 2.3104 - acc: 0.4431 - val_loss: 2.3495 - val_acc: 0.4451\n",
            "Epoch 2/15\n",
            "3125/3125 [==============================] - 491s 157ms/step - loss: 2.2988 - acc: 0.4427 - val_loss: 2.3536 - val_acc: 0.4486\n",
            "Epoch 3/15\n",
            "3125/3125 [==============================] - 493s 158ms/step - loss: 2.2908 - acc: 0.4480 - val_loss: 2.3493 - val_acc: 0.4490\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.44290 to 0.44900, saving model to /content/drive/My Drive/ass4/__32_16_64_32_16_64_32_inb_IMGAUG_epochs:003-acc:0.448-val_acc:0.449.hdf5\n",
            "Epoch 4/15\n",
            "3125/3125 [==============================] - 492s 157ms/step - loss: 2.2805 - acc: 0.4482 - val_loss: 2.3507 - val_acc: 0.4462\n",
            "Epoch 5/15\n",
            "3125/3125 [==============================] - 493s 158ms/step - loss: 2.2735 - acc: 0.4492 - val_loss: 2.3442 - val_acc: 0.4476\n",
            "Epoch 6/15\n",
            "3125/3125 [==============================] - 486s 156ms/step - loss: 2.2653 - acc: 0.4521 - val_loss: 2.3429 - val_acc: 0.4477\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.44900\n",
            "Epoch 7/15\n",
            "3125/3125 [==============================] - 487s 156ms/step - loss: 2.2580 - acc: 0.4529 - val_loss: 2.3295 - val_acc: 0.4500\n",
            "Epoch 8/15\n",
            "3125/3125 [==============================] - 492s 158ms/step - loss: 2.2587 - acc: 0.4524 - val_loss: 2.3209 - val_acc: 0.4521\n",
            "Epoch 9/15\n",
            "3125/3125 [==============================] - 493s 158ms/step - loss: 2.2511 - acc: 0.4538 - val_loss: 2.3243 - val_acc: 0.4538\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.44900 to 0.45380, saving model to /content/drive/My Drive/ass4/__32_16_64_32_16_64_32_inb_IMGAUG_epochs:009-acc:0.454-val_acc:0.454.hdf5\n",
            "Epoch 10/15\n",
            "3125/3125 [==============================] - 496s 159ms/step - loss: 2.2470 - acc: 0.4561 - val_loss: 2.3183 - val_acc: 0.4529\n",
            "Epoch 11/15\n",
            "3125/3125 [==============================] - 492s 157ms/step - loss: 2.2354 - acc: 0.4576 - val_loss: 2.3072 - val_acc: 0.4530\n",
            "Epoch 12/15\n",
            "3125/3125 [==============================] - 494s 158ms/step - loss: 2.2307 - acc: 0.4587 - val_loss: 2.3131 - val_acc: 0.4565\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.45380 to 0.45650, saving model to /content/drive/My Drive/ass4/__32_16_64_32_16_64_32_inb_IMGAUG_epochs:012-acc:0.459-val_acc:0.457.hdf5\n",
            "Epoch 13/15\n",
            "3125/3125 [==============================] - 499s 160ms/step - loss: 2.2301 - acc: 0.4601 - val_loss: 2.3267 - val_acc: 0.4499\n",
            "Epoch 14/15\n",
            "3125/3125 [==============================] - 498s 159ms/step - loss: 2.2244 - acc: 0.4587 - val_loss: 2.3089 - val_acc: 0.4529\n",
            "Epoch 15/15\n",
            "3125/3125 [==============================] - 496s 159ms/step - loss: 2.2196 - acc: 0.4604 - val_loss: 2.3152 - val_acc: 0.4557\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.45650\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5ce1171588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chR8wD_8Gh7q",
        "colab_type": "code",
        "outputId": "24d55046-cbc5-49d4-ad5e-52fadc61dc16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "model_aug.fit_generator(datagen.flow(X_train, Y_train, batch_size= 32),\n",
        "                        steps_per_epoch=X_train.shape[0] // 32,\n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        epochs=15, verbose=1, max_q_size=100,\n",
        "                        callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=3125, validation_data=(array([[[..., epochs=15, verbose=1, callbacks=[<keras.ca..., max_queue_size=100)`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "3125/3125 [==============================] - 492s 157ms/step - loss: 2.2137 - acc: 0.4622 - val_loss: 2.3146 - val_acc: 0.4551\n",
            "Epoch 2/15\n",
            "3125/3125 [==============================] - 490s 157ms/step - loss: 2.2074 - acc: 0.4627 - val_loss: 2.3010 - val_acc: 0.4579\n",
            "Epoch 3/15\n",
            "3125/3125 [==============================] - 500s 160ms/step - loss: 2.2026 - acc: 0.4650 - val_loss: 2.3120 - val_acc: 0.4546\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.45650\n",
            "Epoch 4/15\n",
            "3125/3125 [==============================] - 499s 160ms/step - loss: 2.1975 - acc: 0.4657 - val_loss: 2.3039 - val_acc: 0.4569\n",
            "Epoch 5/15\n",
            "3125/3125 [==============================] - 492s 158ms/step - loss: 2.1911 - acc: 0.4664 - val_loss: 2.2970 - val_acc: 0.4579\n",
            "Epoch 6/15\n",
            "3125/3125 [==============================] - 497s 159ms/step - loss: 2.1888 - acc: 0.4681 - val_loss: 2.3106 - val_acc: 0.4558\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.45650\n",
            "Epoch 7/15\n",
            "3125/3125 [==============================] - 498s 159ms/step - loss: 2.1894 - acc: 0.4675 - val_loss: 2.3028 - val_acc: 0.4544\n",
            "Epoch 8/15\n",
            "3125/3125 [==============================] - 492s 157ms/step - loss: 2.1838 - acc: 0.4698 - val_loss: 2.2931 - val_acc: 0.4590\n",
            "Epoch 9/15\n",
            "3125/3125 [==============================] - 494s 158ms/step - loss: 2.1770 - acc: 0.4693 - val_loss: 2.2984 - val_acc: 0.4603\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.45650 to 0.46030, saving model to /content/drive/My Drive/ass4/__32_16_64_32_16_64_32_inb_IMGAUG_epochs:009-acc:0.469-val_acc:0.460.hdf5\n",
            "Epoch 10/15\n",
            "3125/3125 [==============================] - 497s 159ms/step - loss: 2.1723 - acc: 0.4709 - val_loss: 2.2904 - val_acc: 0.4590\n",
            "Epoch 11/15\n",
            "3125/3125 [==============================] - 497s 159ms/step - loss: 2.1704 - acc: 0.4713 - val_loss: 2.2791 - val_acc: 0.4575\n",
            "Epoch 12/15\n",
            "3125/3125 [==============================] - 501s 160ms/step - loss: 2.1654 - acc: 0.4725 - val_loss: 2.2897 - val_acc: 0.4606\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.46030 to 0.46060, saving model to /content/drive/My Drive/ass4/__32_16_64_32_16_64_32_inb_IMGAUG_epochs:012-acc:0.472-val_acc:0.461.hdf5\n",
            "Epoch 13/15\n",
            "3125/3125 [==============================] - 500s 160ms/step - loss: 2.1643 - acc: 0.4731 - val_loss: 2.2871 - val_acc: 0.4592\n",
            "Epoch 14/15\n",
            "3125/3125 [==============================] - 496s 159ms/step - loss: 2.1557 - acc: 0.4750 - val_loss: 2.2851 - val_acc: 0.4617\n",
            "Epoch 15/15\n",
            "3125/3125 [==============================] - 494s 158ms/step - loss: 2.1569 - acc: 0.4737 - val_loss: 2.2883 - val_acc: 0.4559\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.46060\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5ce1a73be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14QQggtKce9b",
        "colab_type": "code",
        "outputId": "89551d36-3827-4cba-cffb-49e4501969ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "model_aug.fit_generator(datagen.flow(X_train, Y_train, batch_size= 32),\n",
        "                        steps_per_epoch=X_train.shape[0] // 32,\n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        epochs=6, verbose=1, max_q_size=100,\n",
        "                        callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=3125, validation_data=(array([[[..., epochs=6, verbose=1, callbacks=[<keras.ca..., max_queue_size=100)`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "3125/3125 [==============================] - 496s 159ms/step - loss: 2.1507 - acc: 0.4755 - val_loss: 2.2826 - val_acc: 0.4601\n",
            "Epoch 2/6\n",
            "3125/3125 [==============================] - 491s 157ms/step - loss: 2.1492 - acc: 0.4764 - val_loss: 2.2768 - val_acc: 0.4642\n",
            "Epoch 3/6\n",
            "3125/3125 [==============================] - 493s 158ms/step - loss: 2.1514 - acc: 0.4750 - val_loss: 2.2835 - val_acc: 0.4589\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.46060\n",
            "Epoch 4/6\n",
            "3125/3125 [==============================] - 491s 157ms/step - loss: 2.1416 - acc: 0.4761 - val_loss: 2.2769 - val_acc: 0.4603\n",
            "Epoch 5/6\n",
            "3125/3125 [==============================] - 494s 158ms/step - loss: 2.1421 - acc: 0.4783 - val_loss: 2.2771 - val_acc: 0.4613\n",
            "Epoch 6/6\n",
            "3125/3125 [==============================] - 489s 156ms/step - loss: 2.1343 - acc: 0.4779 - val_loss: 2.2765 - val_acc: 0.4593\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.46060\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5ce1ca16d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1QFVrKfFlTE",
        "colab_type": "code",
        "outputId": "f711a477-01a9-4161-d53f-8eb083006a48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "## Loading model from previous checkpoint\n",
        "\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "model_aug = load_model('/content/drive/My Drive/ass4/__32_16_64_32_16_64_32_inb_IMGAUG_epochs:012-acc:0.472-val_acc:0.461.hdf5',custom_objects={'tf': tf})\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TMxfczvG2nV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger, ModelCheckpoint\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
        "csv_logger = CSVLogger('tinyImageNet.csv')\n",
        "\n",
        "filepath=\"/content/drive/My Drive/ass4/__32_16_64_32_16_64_32_inb_IMGAUG2_epochs:{epoch:03d}-acc:{acc:.3f}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=3)\n",
        "callbacks_list = [checkpoint, lr_reducer, csv_logger ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQj36uMxJHwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##datagen already run above"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D01jWEnMJFtJ",
        "colab_type": "code",
        "outputId": "e4809487-72de-4e1f-91c1-c59bd4e56455",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1001
        }
      },
      "source": [
        "datagen.fit(X_train)\n",
        "\n",
        "model_aug.fit_generator(datagen.flow(X_train, Y_train, batch_size= 32),\n",
        "                        steps_per_epoch=X_train.shape[0] // 32,\n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        epochs=9, verbose=1, max_q_size=100,\n",
        "                        callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=3125, validation_data=(array([[[..., epochs=9, verbose=1, callbacks=[<keras.ca..., max_queue_size=100)`\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/9\n",
            "3125/3125 [==============================] - 483s 155ms/step - loss: 2.1674 - acc: 0.4725 - val_loss: 2.2836 - val_acc: 0.4580\n",
            "Epoch 2/9\n",
            "3125/3125 [==============================] - 475s 152ms/step - loss: 2.1627 - acc: 0.4722 - val_loss: 2.2848 - val_acc: 0.4611\n",
            "Epoch 3/9\n",
            " 671/3125 [=====>........................] - ETA: 6:02 - loss: 2.1570 - acc: 0.4753"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=3125, validation_data=(array([[[..., epochs=9, verbose=1, callbacks=[<keras.ca..., max_queue_size=100)`\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/9\n",
            "3125/3125 [==============================] - 483s 155ms/step - loss: 2.1674 - acc: 0.4725 - val_loss: 2.2836 - val_acc: 0.4580\n",
            "Epoch 2/9\n",
            "3125/3125 [==============================] - 475s 152ms/step - loss: 2.1627 - acc: 0.4722 - val_loss: 2.2848 - val_acc: 0.4611\n",
            "Epoch 3/9\n",
            "3125/3125 [==============================] - 475s 152ms/step - loss: 2.1571 - acc: 0.4724 - val_loss: 2.2835 - val_acc: 0.4636\n",
            "3125/3125 [==============================] - 475s 152ms/step - loss: 2.1571 - acc: 0.4724 - val_loss: 2.2835 - val_acc: 0.4636\n",
            "\n",
            "Epoch 00003: val_acc improved from -inf to 0.46360, saving model to /content/drive/My Drive/ass4/__32_16_64_32_16_64_32_inb_IMGAUG2_epochs:003-acc:0.472-val_acc:0.464.hdf5\n",
            "\n",
            "Epoch 00003: val_acc improved from -inf to 0.46360, saving model to /content/drive/My Drive/ass4/__32_16_64_32_16_64_32_inb_IMGAUG2_epochs:003-acc:0.472-val_acc:0.464.hdf5\n",
            "Epoch 4/9\n",
            "   1/3125 [..............................] - ETA: 7:36 - loss: 2.1677 - acc: 0.5312Epoch 4/9\n",
            "3125/3125 [==============================] - 475s 152ms/step - loss: 2.1510 - acc: 0.4735 - val_loss: 2.2790 - val_acc: 0.4615\n",
            "3125/3125 [==============================] - 475s 152ms/step - loss: 2.1510 - acc: 0.4735 - val_loss: 2.2790 - val_acc: 0.4615\n",
            "Epoch 5/9\n",
            "   1/3125 [..............................] - ETA: 7:49 - loss: 2.1664 - acc: 0.4375Epoch 5/9\n",
            "3125/3125 [==============================] - 476s 152ms/step - loss: 2.1517 - acc: 0.4750 - val_loss: 2.2851 - val_acc: 0.4602\n",
            "3125/3125 [==============================] - 476s 152ms/step - loss: 2.1517 - acc: 0.4750 - val_loss: 2.2851 - val_acc: 0.4602\n",
            "Epoch 6/9\n",
            "   1/3125 [..............................] - ETA: 7:56 - loss: 2.2607 - acc: 0.4688Epoch 6/9\n",
            "3125/3125 [==============================] - 476s 152ms/step - loss: 2.1439 - acc: 0.4761 - val_loss: 2.2851 - val_acc: 0.4588\n",
            "3125/3125 [==============================] - 476s 152ms/step - loss: 2.1439 - acc: 0.4761 - val_loss: 2.2851 - val_acc: 0.4588\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.46360\n",
            "Epoch 7/9\n",
            "   1/3125 [..............................] - ETA: 7:36 - loss: 2.2857 - acc: 0.5000\n",
            "Epoch 00006: val_acc did not improve from 0.46360\n",
            "Epoch 7/9\n",
            "3125/3125 [==============================] - 476s 152ms/step - loss: 2.1459 - acc: 0.4769 - val_loss: 2.2729 - val_acc: 0.4616\n",
            "3125/3125 [==============================] - 476s 152ms/step - loss: 2.1459 - acc: 0.4769 - val_loss: 2.2729 - val_acc: 0.4616\n",
            "Epoch 8/9\n",
            "   1/3125 [..............................] - ETA: 7:32 - loss: 2.3787 - acc: 0.4688Epoch 8/9\n",
            "3125/3125 [==============================] - 476s 152ms/step - loss: 2.1445 - acc: 0.4760 - val_loss: 2.2720 - val_acc: 0.4621\n",
            "3125/3125 [==============================] - 476s 152ms/step - loss: 2.1445 - acc: 0.4760 - val_loss: 2.2720 - val_acc: 0.4621\n",
            "Epoch 9/9\n",
            "   1/3125 [..............................] - ETA: 8:01 - loss: 1.6326 - acc: 0.5938Epoch 9/9\n",
            "3125/3125 [==============================] - 480s 153ms/step - loss: 2.1371 - acc: 0.4776 - val_loss: 2.2792 - val_acc: 0.4630\n",
            "3125/3125 [==============================] - 480s 153ms/step - loss: 2.1371 - acc: 0.4776 - val_loss: 2.2792 - val_acc: 0.4630\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.46360\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.46360\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f87a22caf60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f87a22caf60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJdKLRmmbLEo",
        "colab_type": "code",
        "outputId": "24964335-1d0e-4393-d191-f3c5c8c7dd74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "## above log file shows 2 records for same epoch. Perhaps due to reconnecting to the session\n",
        "\n",
        "model_aug.fit_generator(datagen.flow(X_train, Y_train, batch_size= 32),\n",
        "                        steps_per_epoch=X_train.shape[0] // 32,\n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        epochs=3, verbose=1, max_q_size=100,\n",
        "                        callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=3125, validation_data=(array([[[..., epochs=3, verbose=1, callbacks=[<keras.ca..., max_queue_size=100)`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "3125/3125 [==============================] - 481s 154ms/step - loss: 2.1346 - acc: 0.4792 - val_loss: 2.2755 - val_acc: 0.4609\n",
            "Epoch 2/3\n",
            "3125/3125 [==============================] - 479s 153ms/step - loss: 2.1342 - acc: 0.4792 - val_loss: 2.2697 - val_acc: 0.4642\n",
            "Epoch 3/3\n",
            "3125/3125 [==============================] - 479s 153ms/step - loss: 2.1258 - acc: 0.4804 - val_loss: 2.2777 - val_acc: 0.4616\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.46360\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f87a2093f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj60ngVqpB14",
        "colab_type": "text"
      },
      "source": [
        "### Without augmentation 64X64"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx73yELlmRFg",
        "colab_type": "code",
        "outputId": "b8707273-71d3-49f6-ecc7-a2a33176d38a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000, 64, 64, 3)\n",
            "(100000, 200)\n",
            "(10000, 64, 64, 3)\n",
            "(10000, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yjx8cP83qJNK",
        "colab_type": "code",
        "outputId": "e29e1991-11a2-4a49-d46a-72b13037e057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        }
      },
      "source": [
        "## loading model from previous checkpoint\n",
        "\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "model_nor = load_model('/content/drive/My Drive/ass4/__32_16_64_32_16_64_32_inb_IMGAUG2_epochs:003-acc:0.472-val_acc:0.464.hdf5',custom_objects={'tf': tf})\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VMidJW7tkO_",
        "colab_type": "code",
        "outputId": "04d4a534-a0f2-432f-88d4-fb2dbe1a0d55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "score = model_nor.evaluate(X_test, Y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 52s 5ms/step\n",
            "Test loss: 3.499537476348877\n",
            "Test accuracy: 0.2301\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFO8cmGgm4TK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger, ModelCheckpoint\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
        "csv_logger = CSVLogger('tinyImageNet.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVrMlwqTnFer",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath=\"/content/drive/My Drive/ass4/__32_16_64_32_16_64_32_inb_IMGAUG_nor64_epochs:{epoch:03d}-acc:{acc:.3f}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=3)\n",
        "callbacks_list = [checkpoint, lr_reducer, csv_logger ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KufW-ixMnV3B",
        "colab_type": "code",
        "outputId": "0edd7066-6a90-411a-9bd3-69b9b7019502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1245
        }
      },
      "source": [
        "callbacks_list = [checkpoint, lr_reducer, csv_logger ]\n",
        "\n",
        "epochs = 9\n",
        "\n",
        "model_nor.fit(X_train, Y_train,\n",
        "          batch_size=128,\n",
        "          nb_epoch=epochs,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          shuffle=True,\n",
        "          callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 100000 samples, validate on 10000 samples\n",
            "Epoch 1/9\n",
            "100000/100000 [==============================] - 1753s 18ms/step - loss: 2.3240 - acc: 0.4566 - val_loss: 2.4025 - val_acc: 0.4349\n",
            "Epoch 2/9\n",
            "100000/100000 [==============================] - 1734s 17ms/step - loss: 2.1678 - acc: 0.4892 - val_loss: 2.3452 - val_acc: 0.4441\n",
            "Epoch 3/9\n",
            "100000/100000 [==============================] - 1734s 17ms/step - loss: 2.1111 - acc: 0.5003 - val_loss: 2.3075 - val_acc: 0.4528\n",
            "\n",
            "Epoch 00003: val_acc improved from -inf to 0.45280, saving model to /content/drive/My Drive/ass4/__32_16_64_32_16_64_32_inb_IMGAUG_nor64_epochs:003-acc:0.500-val_acc:0.453.hdf5\n",
            "Epoch 4/9\n",
            "100000/100000 [==============================] - 1735s 17ms/step - loss: 2.0752 - acc: 0.5081 - val_loss: 2.2830 - val_acc: 0.4569\n",
            "Epoch 5/9\n",
            "100000/100000 [==============================] - 1736s 17ms/step - loss: 2.0480 - acc: 0.5126 - val_loss: 2.2645 - val_acc: 0.4615\n",
            "Epoch 6/9\n",
            "100000/100000 [==============================] - 1736s 17ms/step - loss: 2.0248 - acc: 0.5173 - val_loss: 2.2512 - val_acc: 0.4671\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.45280 to 0.46710, saving model to /content/drive/My Drive/ass4/__32_16_64_32_16_64_32_inb_IMGAUG_nor64_epochs:006-acc:0.517-val_acc:0.467.hdf5\n",
            "Epoch 7/9\n",
            " 10112/100000 [==>...........................] - ETA: 25:21 - loss: 2.0143 - acc: 0.5194"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-82b0fc9690a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m           callbacks = callbacks_list)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqK3xzK7QGDI",
        "colab_type": "code",
        "outputId": "64b89a1e-8b6f-48c9-ae3a-56b9fb68bdb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "score = model_nor.evaluate(X_test, Y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 47s 5ms/step\n",
            "Test loss: 2.247811727523804\n",
            "Test accuracy: 0.4669\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNCmBWnqdZe4",
        "colab_type": "text"
      },
      "source": [
        "### using CLR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZWS0XIzcv3k",
        "colab_type": "code",
        "outputId": "ffcc270b-70dc-4953-bc3c-68bb294425ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "## loading model from previous checkpoint\n",
        "\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "model_nor = load_model('/content/drive/My Drive/ass4/__32_16_64_32_16_64_32_inb_IMGAUG_nor64_epochs:006-acc:0.517-val_acc:0.467.hdf5',custom_objects={'tf': tf})\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02yrWeBmbTok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Using CLR\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from clr_callback import *\n",
        "\n",
        "filepath=\"/content/drive/My Drive/ass4/__32_16_64_32_16_64_32_inb_IMGAUG_nor64_epochs6+:{epoch:03d}-acc:{acc:.3f}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=3)\n",
        "clr_triangular = CyclicLR(mode='triangular')\n",
        "callbacks_list = [checkpoint, clr_triangular]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KugXVMvc9T6",
        "colab_type": "code",
        "outputId": "bd47d2c6-2748-414d-fd27-67b9d76f6868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1573
        }
      },
      "source": [
        "epochs = 15\n",
        "\n",
        "model_nor.fit(X_train, Y_train,\n",
        "          batch_size=128,\n",
        "          nb_epoch=epochs,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          shuffle=True,\n",
        "          callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 100000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "100000/100000 [==============================] - 1851s 19ms/step - loss: 2.0082 - acc: 0.5204 - val_loss: 2.2407 - val_acc: 0.4672\n",
            "Epoch 2/15\n",
            "100000/100000 [==============================] - 1832s 18ms/step - loss: 1.9967 - acc: 0.5232 - val_loss: 2.2288 - val_acc: 0.4704\n",
            "Epoch 3/15\n",
            "100000/100000 [==============================] - 1832s 18ms/step - loss: 1.9774 - acc: 0.5271 - val_loss: 2.2139 - val_acc: 0.4743\n",
            "\n",
            "Epoch 00003: val_acc improved from -inf to 0.47430, saving model to /content/drive/My Drive/ass4/__32_16_64_32_16_64_32_inb_IMGAUG_nor64_epochs6+:003-acc:0.527-val_acc:0.474.hdf5\n",
            "Epoch 4/15\n",
            "100000/100000 [==============================] - 1833s 18ms/step - loss: 1.9577 - acc: 0.5309 - val_loss: 2.2039 - val_acc: 0.4753\n",
            "Epoch 5/15\n",
            "100000/100000 [==============================] - 1854s 19ms/step - loss: 1.9425 - acc: 0.5339 - val_loss: 2.1964 - val_acc: 0.4787\n",
            "Epoch 6/15\n",
            "100000/100000 [==============================] - 1864s 19ms/step - loss: 1.9356 - acc: 0.5355 - val_loss: 2.1928 - val_acc: 0.4787\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.47430 to 0.47870, saving model to /content/drive/My Drive/ass4/__32_16_64_32_16_64_32_inb_IMGAUG_nor64_epochs6+:006-acc:0.536-val_acc:0.479.hdf5\n",
            "Epoch 7/15\n",
            "100000/100000 [==============================] - 1863s 19ms/step - loss: 1.9311 - acc: 0.5367 - val_loss: 2.1914 - val_acc: 0.4771\n",
            "Epoch 8/15\n",
            "100000/100000 [==============================] - 1863s 19ms/step - loss: 1.9222 - acc: 0.5381 - val_loss: 2.1834 - val_acc: 0.4770\n",
            "Epoch 9/15\n",
            "100000/100000 [==============================] - 1864s 19ms/step - loss: 1.9097 - acc: 0.5393 - val_loss: 2.1726 - val_acc: 0.4821\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.47870 to 0.48210, saving model to /content/drive/My Drive/ass4/__32_16_64_32_16_64_32_inb_IMGAUG_nor64_epochs6+:009-acc:0.539-val_acc:0.482.hdf5\n",
            "Epoch 10/15\n",
            "100000/100000 [==============================] - 1863s 19ms/step - loss: 1.8984 - acc: 0.5425 - val_loss: 2.1683 - val_acc: 0.4819\n",
            "Epoch 11/15\n",
            "100000/100000 [==============================] - 1862s 19ms/step - loss: 1.8909 - acc: 0.5447 - val_loss: 2.1660 - val_acc: 0.4821\n",
            "Epoch 12/15\n",
            "100000/100000 [==============================] - 1864s 19ms/step - loss: 1.8899 - acc: 0.5452 - val_loss: 2.1639 - val_acc: 0.4819\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.48210\n",
            "Epoch 13/15\n",
            "100000/100000 [==============================] - 1863s 19ms/step - loss: 1.8836 - acc: 0.5459 - val_loss: 2.1583 - val_acc: 0.4827\n",
            "Epoch 14/15\n",
            "   128/100000 [..............................] - ETA: 30:13 - loss: 1.9308 - acc: 0.5391"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-b0c87292f124>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           callbacks = callbacks_list)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz5bD9A9MY1S",
        "colab_type": "text"
      },
      "source": [
        "#### Highest accuracy achieved before submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd_--x51wf7D",
        "colab_type": "code",
        "outputId": "e041e994-62d6-4179-eae1-f2412a86fc93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "score = model_nor.evaluate(X_test, Y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 49s 5ms/step\n",
            "Test loss: 2.1580974718093873\n",
            "Test accuracy: 0.4828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox_VU3INvf6l",
        "colab_type": "text"
      },
      "source": [
        "### Training on 16X16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MymLQ4Ro91yH",
        "colab_type": "code",
        "outputId": "5d838bea-9d42-4964-bc70-eb8809419873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000, 16, 16, 3)\n",
            "(100000, 200)\n",
            "(10000, 16, 16, 3)\n",
            "(10000, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tXwlFmIveR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Using CLR\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from clr_callback import *\n",
        "\n",
        "filepath=\"/content/drive/My Drive/ass4/__Block2_inb_IMGAUG_nor64_epochs6_32_16:{epoch:03d}-acc:{acc:.3f}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=3)\n",
        "clr_triangular = CyclicLR(mode='triangular')\n",
        "callbacks_list = [checkpoint, clr_triangular]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9BwRtSwvq_q",
        "colab_type": "code",
        "outputId": "f261b3eb-784a-415c-e078-cbbb63ef9f04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "epochs = 3\n",
        "\n",
        "model_nor.fit(X_train, Y_train,\n",
        "          batch_size=512,\n",
        "          nb_epoch=epochs,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          shuffle=True,\n",
        "          callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 100000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "100000/100000 [==============================] - 104s 1ms/step - loss: 4.6825 - acc: 0.2136 - val_loss: 4.6598 - val_acc: 0.1993\n",
            "Epoch 2/3\n",
            "100000/100000 [==============================] - 100s 1ms/step - loss: 4.2618 - acc: 0.2378 - val_loss: 4.3973 - val_acc: 0.2184\n",
            "Epoch 3/3\n",
            "100000/100000 [==============================] - 100s 1000us/step - loss: 3.9703 - acc: 0.2566 - val_loss: 4.1925 - val_acc: 0.2351\n",
            "\n",
            "Epoch 00003: val_acc improved from -inf to 0.23510, saving model to /content/drive/My Drive/ass4/__Block2_inb_IMGAUG_nor64_epochs6_32_16:003-acc:0.257-val_acc:0.235.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe7f6a4a390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7mhBPPt_GAO",
        "colab_type": "text"
      },
      "source": [
        "### Train on 32X32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd969x6s_I1m",
        "colab_type": "code",
        "outputId": "8c1a6390-0293-486d-b33c-0ee7cc53b9da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000, 32, 32, 3)\n",
            "(100000, 200)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdOh6qtI_KKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Using CLR\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from clr_callback import *\n",
        "\n",
        "filepath=\"/content/drive/My Drive/ass4/__Block2_inb_IMGAUG_nor64_epochs6_32_16_32:{epoch:03d}-acc:{acc:.3f}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=3)\n",
        "clr_triangular = CyclicLR(mode='triangular')\n",
        "callbacks_list = [checkpoint, clr_triangular]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ORP3tx2_TyT",
        "colab_type": "code",
        "outputId": "2d95c44d-e8bc-4c64-90be-4737a2cf3ce2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "epochs = 12\n",
        "\n",
        "model_nor.fit(X_train, Y_train,\n",
        "          batch_size=256,\n",
        "          nb_epoch=epochs,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          shuffle=True,\n",
        "          callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 100000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "100000/100000 [==============================] - 389s 4ms/step - loss: 1.8368 - acc: 0.5401 - val_loss: 2.3552 - val_acc: 0.4524\n",
            "Epoch 2/12\n",
            "100000/100000 [==============================] - 373s 4ms/step - loss: 1.7556 - acc: 0.5577 - val_loss: 2.2991 - val_acc: 0.4613\n",
            "Epoch 3/12\n",
            "100000/100000 [==============================] - 373s 4ms/step - loss: 1.7168 - acc: 0.5661 - val_loss: 2.2752 - val_acc: 0.4659\n",
            "\n",
            "Epoch 00003: val_acc improved from -inf to 0.46590, saving model to /content/drive/My Drive/ass4/__Block2_inb_IMGAUG_nor64_epochs6_32_16_32:003-acc:0.566-val_acc:0.466.hdf5\n",
            "Epoch 4/12\n",
            "100000/100000 [==============================] - 373s 4ms/step - loss: 1.6855 - acc: 0.5749 - val_loss: 2.2565 - val_acc: 0.4677\n",
            "Epoch 5/12\n",
            "100000/100000 [==============================] - 373s 4ms/step - loss: 1.6603 - acc: 0.5807 - val_loss: 2.2453 - val_acc: 0.4708\n",
            "Epoch 6/12\n",
            "100000/100000 [==============================] - 372s 4ms/step - loss: 1.6387 - acc: 0.5864 - val_loss: 2.2325 - val_acc: 0.4727\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.46590 to 0.47270, saving model to /content/drive/My Drive/ass4/__Block2_inb_IMGAUG_nor64_epochs6_32_16_32:006-acc:0.586-val_acc:0.473.hdf5\n",
            "Epoch 7/12\n",
            "100000/100000 [==============================] - 366s 4ms/step - loss: 1.6224 - acc: 0.5904 - val_loss: 2.2288 - val_acc: 0.4748\n",
            "Epoch 8/12\n",
            "100000/100000 [==============================] - 366s 4ms/step - loss: 1.6114 - acc: 0.5924 - val_loss: 2.2223 - val_acc: 0.4763\n",
            "Epoch 9/12\n",
            "100000/100000 [==============================] - 366s 4ms/step - loss: 1.6031 - acc: 0.5950 - val_loss: 2.2201 - val_acc: 0.4773\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.47270 to 0.47730, saving model to /content/drive/My Drive/ass4/__Block2_inb_IMGAUG_nor64_epochs6_32_16_32:009-acc:0.595-val_acc:0.477.hdf5\n",
            "Epoch 10/12\n",
            "100000/100000 [==============================] - 365s 4ms/step - loss: 1.5965 - acc: 0.5965 - val_loss: 2.2187 - val_acc: 0.4777\n",
            "Epoch 11/12\n",
            "100000/100000 [==============================] - 366s 4ms/step - loss: 1.5929 - acc: 0.5980 - val_loss: 2.2178 - val_acc: 0.4782\n",
            "Epoch 12/12\n",
            "100000/100000 [==============================] - 366s 4ms/step - loss: 1.5902 - acc: 0.5989 - val_loss: 2.2166 - val_acc: 0.4791\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.47730 to 0.47910, saving model to /content/drive/My Drive/ass4/__Block2_inb_IMGAUG_nor64_epochs6_32_16_32:012-acc:0.599-val_acc:0.479.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe7f802bd30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp0HxFpgRr6Z",
        "colab_type": "code",
        "outputId": "005571d7-5150-47f9-8c56-34ef13660c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "epochs = 12\n",
        "\n",
        "model_nor.fit(X_train, Y_train,\n",
        "          batch_size=256,\n",
        "          nb_epoch=epochs,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          shuffle=True,\n",
        "          callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 100000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "100000/100000 [==============================] - 366s 4ms/step - loss: 1.5879 - acc: 0.5997 - val_loss: 2.2133 - val_acc: 0.4783\n",
            "Epoch 2/12\n",
            "100000/100000 [==============================] - 366s 4ms/step - loss: 1.5838 - acc: 0.6004 - val_loss: 2.2114 - val_acc: 0.4778\n",
            "Epoch 3/12\n",
            "100000/100000 [==============================] - 366s 4ms/step - loss: 1.5780 - acc: 0.6020 - val_loss: 2.2098 - val_acc: 0.4800\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.47910 to 0.48000, saving model to /content/drive/My Drive/ass4/__Block2_inb_IMGAUG_nor64_epochs6_32_16_32:003-acc:0.602-val_acc:0.480.hdf5\n",
            "Epoch 4/12\n",
            "100000/100000 [==============================] - 366s 4ms/step - loss: 1.5715 - acc: 0.6032 - val_loss: 2.2071 - val_acc: 0.4773\n",
            "Epoch 5/12\n",
            "100000/100000 [==============================] - 366s 4ms/step - loss: 1.5636 - acc: 0.6058 - val_loss: 2.2063 - val_acc: 0.4796\n",
            "Epoch 6/12\n",
            "100000/100000 [==============================] - 366s 4ms/step - loss: 1.5582 - acc: 0.6060 - val_loss: 2.2051 - val_acc: 0.4785\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.48000\n",
            "Epoch 7/12\n",
            "100000/100000 [==============================] - 366s 4ms/step - loss: 1.5538 - acc: 0.6079 - val_loss: 2.2033 - val_acc: 0.4797\n",
            "Epoch 8/12\n",
            "100000/100000 [==============================] - 366s 4ms/step - loss: 1.5496 - acc: 0.6091 - val_loss: 2.2030 - val_acc: 0.4816\n",
            "Epoch 9/12\n",
            "100000/100000 [==============================] - 366s 4ms/step - loss: 1.5490 - acc: 0.6096 - val_loss: 2.2022 - val_acc: 0.4803\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.48000 to 0.48030, saving model to /content/drive/My Drive/ass4/__Block2_inb_IMGAUG_nor64_epochs6_32_16_32:009-acc:0.610-val_acc:0.480.hdf5\n",
            "Epoch 10/12\n",
            "100000/100000 [==============================] - 366s 4ms/step - loss: 1.5464 - acc: 0.6107 - val_loss: 2.2018 - val_acc: 0.4798\n",
            "Epoch 11/12\n",
            "100000/100000 [==============================] - 366s 4ms/step - loss: 1.5465 - acc: 0.6105 - val_loss: 2.2022 - val_acc: 0.4798\n",
            "Epoch 12/12\n",
            "100000/100000 [==============================] - 366s 4ms/step - loss: 1.5442 - acc: 0.6115 - val_loss: 2.2015 - val_acc: 0.4796\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.48030\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe7f6b01358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S6x1ne4plMK",
        "colab_type": "code",
        "outputId": "a99ae49a-c15f-463a-ed09-652d1ef74474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000, 64, 64, 3)\n",
            "(100000, 200)\n",
            "(10000, 64, 64, 3)\n",
            "(10000, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrO8zPbzveBD",
        "colab_type": "code",
        "outputId": "2b64b013-b9ee-406e-8f78-ee022400165d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "## loading model from previous checkpoint\n",
        "\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "model_nor = load_model('/content/drive/My Drive/ass4/__Block2_inb_IMGAUG_nor64_epochs6_32_16_32:009-acc:0.610-val_acc:0.480.hdf5',custom_objects={'tf': tf})\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HKoiYy2wAVO",
        "colab_type": "code",
        "outputId": "c66d0b7b-6238-477e-8083-925cdf1ff066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1245
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from clr_callback import *\n",
        "filepath=\"/content/drive/My Drive/ass4/_Blocks2_inb_IMGAUG_nor64_48_32aug2_noAug_final:{epoch:03d}-acc:{acc:.3f}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "clr_triangular = CyclicLR(mode='triangular')\n",
        "callbacks_list = [checkpoint, clr_triangular]\n",
        "\n",
        "epochs = 9\n",
        "\n",
        "model_nor.fit(X_train, Y_train,\n",
        "          batch_size=128,\n",
        "          nb_epoch=epochs,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          shuffle=True,\n",
        "          callbacks = callbacks_list)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 100000 samples, validate on 10000 samples\n",
            "Epoch 1/9\n",
            "100000/100000 [==============================] - 1878s 19ms/step - loss: 2.1521 - acc: 0.4903 - val_loss: 2.2926 - val_acc: 0.4537\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.45370, saving model to /content/drive/My Drive/ass4/_Blocks2_inb_IMGAUG_nor64_48_32aug2_noAug_final:001-acc:0.490-val_acc:0.454.hdf5\n",
            "Epoch 2/9\n",
            "100000/100000 [==============================] - 1850s 18ms/step - loss: 1.9970 - acc: 0.5232 - val_loss: 2.2241 - val_acc: 0.4705\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.45370 to 0.47050, saving model to /content/drive/My Drive/ass4/_Blocks2_inb_IMGAUG_nor64_48_32aug2_noAug_final:002-acc:0.523-val_acc:0.470.hdf5\n",
            "Epoch 3/9\n",
            "100000/100000 [==============================] - 1852s 19ms/step - loss: 1.9377 - acc: 0.5362 - val_loss: 2.1879 - val_acc: 0.4766\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.47050 to 0.47660, saving model to /content/drive/My Drive/ass4/_Blocks2_inb_IMGAUG_nor64_48_32aug2_noAug_final:003-acc:0.536-val_acc:0.477.hdf5\n",
            "Epoch 4/9\n",
            "100000/100000 [==============================] - 1853s 19ms/step - loss: 1.9044 - acc: 0.5434 - val_loss: 2.1700 - val_acc: 0.4812\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.47660 to 0.48120, saving model to /content/drive/My Drive/ass4/_Blocks2_inb_IMGAUG_nor64_48_32aug2_noAug_final:004-acc:0.543-val_acc:0.481.hdf5\n",
            "Epoch 5/9\n",
            " 51200/100000 [==============>...............] - ETA: 14:42 - loss: 1.8959 - acc: 0.5450"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-d7b971c37f27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m           callbacks = callbacks_list)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV1aAqD-xxD9",
        "colab_type": "code",
        "outputId": "6642d7a4-387c-4fa3-981c-27b4b614b91f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "score = model_nor.evaluate(X_test, Y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 49s 5ms/step\n",
            "Test loss: 2.1683026433944703\n",
            "Test accuracy: 0.4816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKRL3yNhQ0ZS",
        "colab_type": "code",
        "outputId": "d5687f34-5059-4735-a02b-7320d66c42d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        }
      },
      "source": [
        "model_nor.fit(X_train, Y_train,\n",
        "          batch_size=128,\n",
        "          nb_epoch=15,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          shuffle=True,\n",
        "          callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 100000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "100000/100000 [==============================] - 1857s 19ms/step - loss: 1.8815 - acc: 0.5482 - val_loss: 2.1649 - val_acc: 0.4816\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.48120 to 0.48160, saving model to /content/drive/My Drive/ass4/_Blocks2_inb_IMGAUG_nor64_48_32aug2_noAug_final:001-acc:0.548-val_acc:0.482.hdf5\n",
            "Epoch 2/15\n",
            " 17024/100000 [====>.........................] - ETA: 24:55 - loss: 1.8688 - acc: 0.5468"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6hy6_ZxXLqb",
        "colab_type": "code",
        "outputId": "e4edbc97-569e-49cd-8735-d76f7aa99d71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "## loading model from previous checkpoint\n",
        "\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "model_nor = load_model('/content/drive/My Drive/ass4/_Blocks2_inb_IMGAUG_nor64_48_32aug2_noAug_final:001-acc:0.548-val_acc:0.482.hdf5',custom_objects={'tf': tf})\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64Ek99PkwQRO",
        "colab_type": "code",
        "outputId": "5b63639d-d411-4d22-b8e3-478e79285f99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1055
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from clr_callback import *\n",
        "filepath=\"/content/drive/My Drive/ass4/_After_final:{epoch:03d}-acc:{acc:.3f}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=3)\n",
        "clr_triangular = CyclicLR(mode='triangular')\n",
        "callbacks_list = [checkpoint, clr_triangular]\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "model_nor.fit(X_train, Y_train,\n",
        "          batch_size=128,\n",
        "          nb_epoch=epochs,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          shuffle=True,\n",
        "          callbacks = callbacks_list)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 100000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "100000/100000 [==============================] - 2069s 21ms/step - loss: 1.8759 - acc: 0.5492 - val_loss: 2.1602 - val_acc: 0.4825\n",
            "Epoch 2/20\n",
            "100000/100000 [==============================] - 2043s 20ms/step - loss: 1.8703 - acc: 0.5505 - val_loss: 2.1547 - val_acc: 0.4810\n",
            "Epoch 3/20\n",
            "100000/100000 [==============================] - 2069s 21ms/step - loss: 1.8608 - acc: 0.5519 - val_loss: 2.1491 - val_acc: 0.4840\n",
            "\n",
            "Epoch 00003: val_acc improved from -inf to 0.48400, saving model to /content/drive/My Drive/ass4/_After_final:003-acc:0.552-val_acc:0.484.hdf5\n",
            "Epoch 4/20\n",
            "100000/100000 [==============================] - 2071s 21ms/step - loss: 1.8488 - acc: 0.5544 - val_loss: 2.1419 - val_acc: 0.4858\n",
            "Epoch 5/20\n",
            "100000/100000 [==============================] - 2067s 21ms/step - loss: 1.8410 - acc: 0.5559 - val_loss: 2.1367 - val_acc: 0.4877\n",
            "Epoch 6/20\n",
            "100000/100000 [==============================] - 2054s 21ms/step - loss: 1.8359 - acc: 0.5561 - val_loss: 2.1359 - val_acc: 0.4871\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.48400 to 0.48710, saving model to /content/drive/My Drive/ass4/_After_final:006-acc:0.556-val_acc:0.487.hdf5\n",
            "Epoch 7/20\n",
            "100000/100000 [==============================] - 2058s 21ms/step - loss: 1.8342 - acc: 0.5569 - val_loss: 2.1347 - val_acc: 0.4889\n",
            "Epoch 8/20\n",
            "100000/100000 [==============================] - 2057s 21ms/step - loss: 1.8305 - acc: 0.5581 - val_loss: 2.1328 - val_acc: 0.4865\n",
            "Epoch 9/20\n",
            "100000/100000 [==============================] - 2055s 21ms/step - loss: 1.8217 - acc: 0.5598 - val_loss: 2.1271 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.48710 to 0.49020, saving model to /content/drive/My Drive/ass4/_After_final:009-acc:0.560-val_acc:0.490.hdf5\n",
            "Epoch 10/20\n",
            "100000/100000 [==============================] - 2056s 21ms/step - loss: 1.8131 - acc: 0.5610 - val_loss: 2.1227 - val_acc: 0.4883\n",
            "Epoch 11/20\n",
            "100000/100000 [==============================] - 2059s 21ms/step - loss: 1.8086 - acc: 0.5621 - val_loss: 2.1232 - val_acc: 0.4882\n",
            "Epoch 12/20\n",
            "100000/100000 [==============================] - 2060s 21ms/step - loss: 1.8081 - acc: 0.5623 - val_loss: 2.1242 - val_acc: 0.4877\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.49020\n",
            "Epoch 13/20\n",
            "100000/100000 [==============================] - 2059s 21ms/step - loss: 1.8061 - acc: 0.5620 - val_loss: 2.1234 - val_acc: 0.4904\n",
            "Epoch 14/20\n",
            "100000/100000 [==============================] - 2068s 21ms/step - loss: 1.8023 - acc: 0.5643 - val_loss: 2.1153 - val_acc: 0.4914\n",
            "Epoch 15/20\n",
            "100000/100000 [==============================] - 2066s 21ms/step - loss: 1.7930 - acc: 0.5660 - val_loss: 2.1132 - val_acc: 0.4915\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.49020 to 0.49150, saving model to /content/drive/My Drive/ass4/_After_final:015-acc:0.566-val_acc:0.491.hdf5\n",
            "Epoch 16/20\n",
            "100000/100000 [==============================] - 2065s 21ms/step - loss: 1.7895 - acc: 0.5664 - val_loss: 2.1135 - val_acc: 0.4909\n",
            "Epoch 17/20\n",
            "100000/100000 [==============================] - 2064s 21ms/step - loss: 1.7887 - acc: 0.5666 - val_loss: 2.1134 - val_acc: 0.4901\n",
            "Epoch 18/20\n",
            "100000/100000 [==============================] - 2064s 21ms/step - loss: 1.7894 - acc: 0.5672 - val_loss: 2.1117 - val_acc: 0.4897\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.49150\n",
            "Epoch 19/20\n",
            "100000/100000 [==============================] - 2062s 21ms/step - loss: 1.7844 - acc: 0.5669 - val_loss: 2.1088 - val_acc: 0.4920\n",
            "Epoch 20/20\n",
            "100000/100000 [==============================] - 2065s 21ms/step - loss: 1.7777 - acc: 0.5682 - val_loss: 2.1039 - val_acc: 0.4918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f70b4c25898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiwkKsnMbd56",
        "colab_type": "code",
        "outputId": "a96b8f5e-f8b7-4851-984a-b338a94a9272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "## Loading model from previous checkpoint\n",
        "#  content/drive/My Drive/ass4/_After_final2:009-acc:0.570-val_acc:0.492.hdf5\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "model_aug = load_model('/content/drive/My Drive/ass4/_After_final:015-acc:0.566-val_acc:0.491.hdf5',custom_objects={'tf': tf})\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYTS5vReb3N4",
        "colab_type": "code",
        "outputId": "8ae14f46-abbb-44e1-e65f-4b9e4c5603a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000, 64, 64, 3)\n",
            "(100000, 200)\n",
            "(10000, 64, 64, 3)\n",
            "(10000, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9s40QmRb9NP",
        "colab_type": "code",
        "outputId": "0f3f5217-5ab9-48db-aa09-9a579d2813dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "score = model_aug.evaluate(X_test, Y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 52s 5ms/step\n",
            "Test loss: 2.113161389923096\n",
            "Test accuracy: 0.4914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1K9DPErSOcu",
        "colab_type": "code",
        "outputId": "8aaa97cf-2fc3-41ea-ab22-3be2434c6f93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from clr_callback import *\n",
        "filepath=\"/content/drive/My Drive/ass4/_After_final2:{epoch:03d}-acc:{acc:.3f}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=3)\n",
        "clr_triangular = CyclicLR(mode='triangular')\n",
        "callbacks_list = [checkpoint, clr_triangular]\n",
        "\n",
        "epochs = 21\n",
        "\n",
        "model_aug.fit(X_train, Y_train,\n",
        "          batch_size=128,\n",
        "          nb_epoch=epochs,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          shuffle=True,\n",
        "          callbacks = callbacks_list)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 100000 samples, validate on 10000 samples\n",
            "Epoch 1/21\n",
            "100000/100000 [==============================] - 1784s 18ms/step - loss: 1.7888 - acc: 0.5672 - val_loss: 2.1134 - val_acc: 0.4893\n",
            "Epoch 2/21\n",
            "100000/100000 [==============================] - 1760s 18ms/step - loss: 1.7888 - acc: 0.5666 - val_loss: 2.1152 - val_acc: 0.4890\n",
            "Epoch 3/21\n",
            "100000/100000 [==============================] - 1762s 18ms/step - loss: 1.7869 - acc: 0.5652 - val_loss: 2.1115 - val_acc: 0.4913\n",
            "\n",
            "Epoch 00003: val_acc improved from -inf to 0.49130, saving model to /content/drive/My Drive/ass4/_After_final2:003-acc:0.565-val_acc:0.491.hdf5\n",
            "Epoch 4/21\n",
            "100000/100000 [==============================] - 1763s 18ms/step - loss: 1.7822 - acc: 0.5671 - val_loss: 2.1072 - val_acc: 0.4903\n",
            "Epoch 5/21\n",
            "100000/100000 [==============================] - 1761s 18ms/step - loss: 1.7743 - acc: 0.5690 - val_loss: 2.1043 - val_acc: 0.4912\n",
            "Epoch 6/21\n",
            "100000/100000 [==============================] - 1767s 18ms/step - loss: 1.7711 - acc: 0.5706 - val_loss: 2.1068 - val_acc: 0.4911\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.49130\n",
            "Epoch 7/21\n",
            "100000/100000 [==============================] - 1767s 18ms/step - loss: 1.7728 - acc: 0.5705 - val_loss: 2.1057 - val_acc: 0.4914\n",
            "Epoch 8/21\n",
            "100000/100000 [==============================] - 1765s 18ms/step - loss: 1.7706 - acc: 0.5699 - val_loss: 2.1027 - val_acc: 0.4917\n",
            "Epoch 9/21\n",
            "100000/100000 [==============================] - 1765s 18ms/step - loss: 1.7660 - acc: 0.5700 - val_loss: 2.1006 - val_acc: 0.4925\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.49130 to 0.49250, saving model to /content/drive/My Drive/ass4/_After_final2:009-acc:0.570-val_acc:0.492.hdf5\n",
            "Epoch 10/21\n",
            "100000/100000 [==============================] - 1763s 18ms/step - loss: 1.7613 - acc: 0.5728 - val_loss: 2.0985 - val_acc: 0.4944\n",
            "Epoch 11/21\n",
            "100000/100000 [==============================] - 1761s 18ms/step - loss: 1.7565 - acc: 0.5725 - val_loss: 2.0987 - val_acc: 0.4932\n",
            "Epoch 12/21\n",
            " 89344/100000 [=========================>....] - ETA: 3:03 - loss: 1.7546 - acc: 0.5731"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwqOS7eUuQBz",
        "colab_type": "text"
      },
      "source": [
        "## After Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP1I2XEeuAX3",
        "colab_type": "code",
        "outputId": "317ba591-99db-4332-f4b2-8958cf3281f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 930
        }
      },
      "source": [
        "## Loading model from previous checkpoint \n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "model_aug = load_model('/content/drive/My Drive/ass4/_After_final2:009-acc:0.570-val_acc:0.492.hdf5',custom_objects={'tf': tf})\n",
        "\n",
        "\n",
        "score = model_aug.evaluate(X_test, Y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "10000/10000 [==============================] - 52s 5ms/step\n",
            "Test loss: 2.1005806678771974\n",
            "Test accuracy: 0.4925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93YXXSW2SSE5",
        "colab_type": "code",
        "outputId": "b61e37ab-8057-4e54-c451-13b1d7ec75b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from clr_callback import *\n",
        "filepath=\"/content/drive/My Drive/ass4/_After_final3:{epoch:03d}-acc:{acc:.3f}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "clr_triangular = CyclicLR(mode='triangular')\n",
        "callbacks_list = [checkpoint, clr_triangular]\n",
        "\n",
        "epochs = 21\n",
        "\n",
        "model_aug.fit(X_train, Y_train,\n",
        "          batch_size=128,\n",
        "          nb_epoch=epochs,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          shuffle=True,\n",
        "          callbacks = callbacks_list)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 100000 samples, validate on 10000 samples\n",
            "Epoch 1/21\n",
            "100000/100000 [==============================] - 1771s 18ms/step - loss: 1.7604 - acc: 0.5725 - val_loss: 2.1001 - val_acc: 0.4933\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.49330, saving model to /content/drive/My Drive/ass4/_After_final3:001-acc:0.573-val_acc:0.493.hdf5\n",
            "Epoch 2/21\n",
            "100000/100000 [==============================] - 1755s 18ms/step - loss: 1.7606 - acc: 0.5718 - val_loss: 2.1003 - val_acc: 0.4926\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.49330\n",
            "Epoch 3/21\n",
            "100000/100000 [==============================] - 1751s 18ms/step - loss: 1.7585 - acc: 0.5723 - val_loss: 2.0965 - val_acc: 0.4946\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.49330 to 0.49460, saving model to /content/drive/My Drive/ass4/_After_final3:003-acc:0.572-val_acc:0.495.hdf5\n",
            "Epoch 4/21\n",
            "100000/100000 [==============================] - 1766s 18ms/step - loss: 1.7548 - acc: 0.5718 - val_loss: 2.0946 - val_acc: 0.4941\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.49460\n",
            "Epoch 5/21\n",
            "100000/100000 [==============================] - 1761s 18ms/step - loss: 1.7483 - acc: 0.5753 - val_loss: 2.0929 - val_acc: 0.4940\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.49460\n",
            "Epoch 6/21\n",
            "100000/100000 [==============================] - 1753s 18ms/step - loss: 1.7450 - acc: 0.5749 - val_loss: 2.0924 - val_acc: 0.4946\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.49460\n",
            "Epoch 7/21\n",
            " 48768/100000 [=============>................] - ETA: 14:32 - loss: 1.7440 - acc: 0.5769"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}